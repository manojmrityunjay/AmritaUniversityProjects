{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 8830490,
          "sourceType": "datasetVersion",
          "datasetId": 5313186
        }
      ],
      "dockerImageVersionId": 30733,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "XIOT_mj",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manojmrityunjay/AmritaUniversityProjects/blob/main/XIOT_mj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'cb-en-p2aie22006-manojvs:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5313186%2F8830490%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240702%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240702T183417Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D0e5ac50dfc6e57d723db42e412e3687083341c711ee40a3cb7603c5f5e8df61d9f769b0bc37636342c71bf4cdfbc0afad092d7b7e09ac7675a3ad2ce220e92c99fc3b97fd0e10c2a45e07e4abee41ea12c5e79d04b9f253bfe04b76db180e248a93d170715f93d241ae06752a1c011d36eb1be6de6a3640d493d9221e79a6bfebc8b940976e7dd0b185941498d5134ba93fc686dd444cf4275819e299a4dba80f1928b9f740a87510c82228b0696967b03fe2abdfed0653d64d057ae68be6984e19d51afd8ed39ffc85399e754dba465a794336a6c494f5f16388345c236102c8cc1e5f9268966406885512c241ab2534e817bf36bd643c723081ea5f7607e15'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "M4Se6mjqu1Zi",
        "outputId": "24df4560-4f65-410b-ea4b-28e7c34273f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading cb-en-p2aie22006-manojvs, 114840957 bytes compressed\n",
            "[==================================================] 114840957 bytes downloaded\n",
            "Downloaded and uncompressed: cb-en-p2aie22006-manojvs\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORT LIBRARIES**"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-01T11:20:56.21387Z",
          "iopub.execute_input": "2024-07-01T11:20:56.214695Z",
          "iopub.status.idle": "2024-07-01T11:20:56.220815Z",
          "shell.execute_reply.started": "2024-07-01T11:20:56.214658Z",
          "shell.execute_reply": "2024-07-01T11:20:56.21959Z"
        },
        "id": "I5_xk_S_u1Zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "# Filter DeprecationWarnings to avoid cluttering output\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# Filter DtypeWarnings that might arise from mismatched data types\n",
        "# (e.g., when converting between cuDF and Pandas)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T18:00:23.947192Z",
          "iopub.execute_input": "2024-07-02T18:00:23.947581Z",
          "iopub.status.idle": "2024-07-02T18:00:23.960154Z",
          "shell.execute_reply.started": "2024-07-02T18:00:23.947549Z",
          "shell.execute_reply": "2024-07-02T18:00:23.959195Z"
        },
        "trusted": true,
        "id": "Ms49vOG7u1Zi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy matplotlib seaborn tabulate scikit-learn imblearn stable-baselines3\n"
      ],
      "metadata": {
        "id": "wdRWMmyIvVAw",
        "outputId": "0d36f486-8c1a-41ca-f83d-6b521dd7eed5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Collecting imblearn\n",
            "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (from imblearn) (0.10.1)\n",
            "Collecting gymnasium<0.30,>=0.28.1 (from stable-baselines3)\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.3.0+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium<0.30,>=0.28.1->stable-baselines3)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable-baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable-baselines3) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3) (1.3.0)\n",
            "Installing collected packages: farama-notifications, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, gymnasium, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, imblearn, stable-baselines3\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1 imblearn-0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 stable-baselines3-2.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cupy-cuda11x --pre -U -f https://pip.cupy.dev/pre"
      ],
      "metadata": {
        "id": "dInCAcV5v8ZH",
        "outputId": "04832b5d-0b79-48a2-dfce-9052fdad8bfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pip.cupy.dev/pre\n",
            "Collecting cupy-cuda11x\n",
            "  Downloading cupy_cuda11x-13.2.0-cp310-cp310-manylinux2014_x86_64.whl (95.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.4/95.4 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda11x) (1.25.2)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda11x) (0.8.2)\n",
            "Installing collected packages: cupy-cuda11x\n",
            "Successfully installed cupy-cuda11x-13.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cupy",
                  "cupy_backends",
                  "cupyx"
                ]
              },
              "id": "536a8fd42a954aedac3188551fb93d88"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "Swv0Wh8PvoL3",
        "outputId": "79002cf2-cd23-47b3-b420-c6d15dc9de19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jul  2 18:42:01 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8               9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "# !chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "# !bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "# !conda init\n"
      ],
      "metadata": {
        "id": "Bab5DxrvxNP9",
        "outputId": "1f398ad5-2b11-4e63-9501-70fd5a1bfbd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-02 18:46:18--  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.176.84, 104.18.177.84, 2606:4700::6812:b054, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.176.84|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh [following]\n",
            "--2024-07-02 18:46:18--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.32.241, 104.16.191.158, 2606:4700::6810:bf9e, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.32.241|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 146836934 (140M) [application/octet-stream]\n",
            "Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-latest-L 100%[===================>] 140.03M  66.3MB/s    in 2.1s    \n",
            "\n",
            "2024-07-02 18:46:21 (66.3 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [146836934/146836934]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "\n",
            "Installing base environment...\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "no change     /usr/local/condabin/conda\n",
            "no change     /usr/local/bin/conda\n",
            "no change     /usr/local/bin/conda-env\n",
            "no change     /usr/local/bin/activate\n",
            "no change     /usr/local/bin/deactivate\n",
            "no change     /usr/local/etc/profile.d/conda.sh\n",
            "no change     /usr/local/etc/fish/conf.d/conda.fish\n",
            "no change     /usr/local/shell/condabin/Conda.psm1\n",
            "no change     /usr/local/shell/condabin/conda-hook.ps1\n",
            "no change     /usr/local/lib/python3.12/site-packages/xontrib/conda.xsh\n",
            "no change     /usr/local/etc/profile.d/conda.csh\n",
            "modified      /root/.bashrc\n",
            "\n",
            "==> For changes to take effect, close and re-open your current shell. <==\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !conda create -n rapids-env -c rapidsai -c nvidia -c conda-forge rapids=23.02 python=3.8 cudatoolkit=11.2 -y\n",
        "# !conda activate rapids-env\n"
      ],
      "metadata": {
        "id": "ljVLmzCmxQE9",
        "outputId": "84d349a5-42d9-4956-e393-e39301d0f6e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-dev-10.3.0 | 53.7 MB   | :  51% 0.5089464485453401/1 [01:31<00:16, 34.24s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :  39% 0.38991073868355575/1 [01:31<00:26, 43.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-dev-10.3.0 | 53.7 MB   | :  59% 0.5909595333966463/1 [01:31<00:09, 23.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :  45% 0.4492808330329552/1 [01:31<00:16, 30.13s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-dev-10.3.0 | 53.7 MB   | :  69% 0.6942029558158439/1 [01:31<00:04, 14.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :  50% 0.5046458019698951/1 [01:31<00:10, 21.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-dev-10.3.0 | 53.7 MB   | :  78% 0.7762160406671501/1 [01:31<00:02, 10.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.0.86  | 53.2 MB   | :   0% 0.00029378014500947795/1 [01:31<86:39:49, 312080.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :  56% 0.5628379182568064/1 [01:31<00:06, 15.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-dev-10.3.0 | 53.7 MB   | :  86% 0.8576474724344045/1 [01:31<00:01,  7.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.0.86  | 53.2 MB   | :   8% 0.07550149726743582/1 [01:31<13:08, 852.38s/it]         \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :  62% 0.618438482806244/1 [01:31<00:04, 11.64s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.0.86  | 53.2 MB   | :  15% 0.14865275337479583/1 [01:31<05:04, 358.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-dev-10.3.0 | 53.7 MB   | :  94% 0.9379155980335553/1 [01:31<00:00,  6.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :  67% 0.668855943880734/1 [01:31<00:02,  9.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.0.86  | 53.2 MB   | :  22% 0.21739730730701368/1 [01:32<02:38, 201.90s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :  74% 0.7350583109925642/1 [01:32<00:01,  6.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.0.86  | 53.2 MB   | :  29% 0.28526052080420305/1 [01:32<01:29, 125.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :  79% 0.7890097062545185/1 [01:32<00:01,  5.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.0.86  | 53.2 MB   | :  35% 0.35106727328632614/1 [01:32<00:53, 82.54s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :  85% 0.8457882488664442/1 [01:32<00:00,  4.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.0.86  | 53.2 MB   | :  42% 0.4233371889586577/1 [01:32<00:31, 54.03s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :  91% 0.9063363212783316/1 [01:32<00:00,  3.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.0.86  | 53.2 MB   | :  50% 0.49766356564605563/1 [01:32<00:18, 36.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-dev-11.4 | 66.3 MB   | :  96% 0.9612300989902763/1 [01:32<00:00,  3.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.0.86  | 53.2 MB   | :  57% 0.5687583607383493/1 [01:32<00:10, 25.07s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.0.86  | 53.2 MB   | :  64% 0.638090474960586/1 [01:32<00:06, 17.85s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libfaiss-1.7.2       | 51.4 MB   | :   0% 0.0003040711158199902/1 [01:32<84:38:08, 304781.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.0.86  | 53.2 MB   | :  71% 0.706247468602785/1 [01:32<00:03, 12.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libfaiss-1.7.2       | 51.4 MB   | :   7% 0.0741933522600776/1 [01:32<13:31, 876.84s/it]         \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.0.86  | 53.2 MB   | :  79% 0.7902685900754957/1 [01:32<00:01,  8.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libfaiss-1.7.2       | 51.4 MB   | :  17% 0.16875946928009455/1 [01:32<04:18, 311.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.0.86  | 53.2 MB   | :  86% 0.8616571653127988/1 [01:32<00:00,  6.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libfaiss-1.7.2       | 51.4 MB   | :  25% 0.25298716836223184/1 [01:32<02:08, 171.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.0.86  | 53.2 MB   | :  96% 0.9594859536009549/1 [01:33<00:00,  4.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libfaiss-1.7.2       | 51.4 MB   | :  34% 0.33660672521272916/1 [01:33<01:09, 105.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libfaiss-1.7.2       | 51.4 MB   | :  42% 0.4217466376423264/1 [01:33<00:39, 67.47s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libfaiss-1.7.2       | 51.4 MB   | :  51% 0.5114476168092235/1 [01:33<00:21, 44.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libfaiss-1.7.2       | 51.4 MB   | :  60% 0.5956753158913608/1 [01:33<00:12, 30.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libfaiss-1.7.2       | 51.4 MB   | :  67% 0.6723012370779983/1 [01:33<00:07, 22.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libfaiss-1.7.2       | 51.4 MB   | :  74% 0.7395009536742162/1 [01:33<00:04, 16.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libfaiss-1.7.2       | 51.4 MB   | :  84% 0.8352833551575131/1 [01:33<00:01, 11.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libfaiss-1.7.2       | 51.4 MB   | :  91% 0.9103889207650506/1 [01:33<00:00,  8.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libfaiss-1.7.2       | 51.4 MB   | :  98% 0.9812374907511083/1 [01:34<00:00,  6.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libcublas-11.11.3.6  | 364.0 MB  | : 100% 1.0/1 [02:56<00:00, 3427.74s/it]             \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libcublas-11.11.3.6  | 364.0 MB  | : 100% 1.0/1 [02:56<00:00, 3427.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcublas-dev-11.11. | 394.1 MB  | : 100% 1.0/1 [03:09<00:00, 12.80s/it]               \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcudf-23.02.00     | 284.0 MB  | : 100% 1.0/1 [04:06<00:00,  9.12s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libcugraph-23.02.00  | 537.0 MB  | : 100% 1.0/1 [04:33<00:00, 15.41s/it]              \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-dev-11.7 | 359.7 MB  | : 100% 1.0/1 [05:39<00:00, 10810.62s/it]            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-dev-11.7 | 359.7 MB  | : 100% 1.0/1 [05:39<00:00, 10810.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | : 100% 1.0/1 [06:12<00:00,  5.39s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libraft-distance-23. | 666.4 MB  | : 100% 1.0/1 [06:16<00:00, 41.03s/it]               \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxgboost-1.7.1dev. | 234.3 MB  | : 100% 1.0/1 [07:01<00:00,  7.24s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcuml-23.02.00     | 255.5 MB  | : 100% 1.0/1 [07:02<00:00, 60.60s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "nccl-2.21.5.1        | 100.9 MB  | : 100% 1.0/1 [07:04<00:00,  3.91s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | : 100% 1.0/1 [07:31<00:00,  3.46s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcugraphops-23.02. | 224.9 MB  | : 100% 1.0/1 [07:45<00:00,  6.70s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | : 100% 1.0/1 [08:01<00:00, 5272.64s/it]            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | : 100% 1.0/1 [08:01<00:00, 5272.64s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-dev-10.3.0 | 53.7 MB   | : 100% 1.0/1 [08:10<00:00,  6.09s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libraft-nn-23.02.00  | 152.2 MB  | : 100% 1.0/1 [08:16<00:00,  4.79s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.0.86  | 53.2 MB   | : 100% 1.0/1 [08:29<00:00,  4.67s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libfaiss-1.7.2       | 51.4 MB   | : 100% 1.0/1 [08:32<00:00,  6.56s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cudatoolkit-11.2.72  | 933.4 MB  | : 100% 1.0/1 [11:27<00:00, 125.16s/it]               \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                         \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                          \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                           \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                          \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "\n",
            "The following PRELINK MESSAGES are INCLUDED:\n",
            "\n",
            "\n",
            "  File nvcomp.txt:\n",
            "\n",
            "  By downloading and using the libcudf conda package, you accept the terms\n",
            "  and conditions of the NVIDIA NVCOMP Software License Agreement:\n",
            "    https://developer.download.nvidia.com/compute/nvcomp/2.3/LICENSE.txt\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "\b\b| \b\b/ \b\b- \b\b\\ \b\b| By downloading and using the CubinLinker conda packages, you accept the terms and conditions of the CubinLinker License Agreement: https://docs.rapids.ai/licenses/CubinLinker.txt\n",
            "\n",
            "\b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate rapids-env\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "\n",
            "CondaError: Run 'conda init' before 'conda activate'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda init"
      ],
      "metadata": {
        "id": "Ey8D4HPu3CSZ",
        "outputId": "25212257-0899-48a1-c7b2-ce28b1ff2875",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no change     /usr/local/condabin/conda\n",
            "no change     /usr/local/bin/conda\n",
            "no change     /usr/local/bin/conda-env\n",
            "no change     /usr/local/bin/activate\n",
            "no change     /usr/local/bin/deactivate\n",
            "no change     /usr/local/etc/profile.d/conda.sh\n",
            "no change     /usr/local/etc/fish/conf.d/conda.fish\n",
            "no change     /usr/local/shell/condabin/Conda.psm1\n",
            "no change     /usr/local/shell/condabin/conda-hook.ps1\n",
            "no change     /usr/local/lib/python3.12/site-packages/xontrib/conda.xsh\n",
            "no change     /usr/local/etc/profile.d/conda.csh\n",
            "no change     /root/.bashrc\n",
            "No action taken.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda activate rapids-env\n"
      ],
      "metadata": {
        "id": "NEFqbLtx3ore",
        "outputId": "91aa9e8d-e3ce-4e06-a9c9-d4aead82efa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CondaError: Run 'conda init' before 'conda activate'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dyn_mjpu1.py (Complete IDS Model with ML, RL, and DL on Kaggle)\n",
        "\n",
        "import cudf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from tabulate import tabulate\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, make_scorer, matthews_corrcoef,\n",
        ")\n",
        "from datetime import datetime\n",
        "from stable_baselines3 import PPO\n",
        "from IPython.display import display\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T18:01:04.205993Z",
          "iopub.execute_input": "2024-07-02T18:01:04.206329Z",
          "iopub.status.idle": "2024-07-02T18:01:04.215211Z",
          "shell.execute_reply.started": "2024-07-02T18:01:04.206285Z",
          "shell.execute_reply": "2024-07-02T18:01:04.214486Z"
        },
        "trusted": true,
        "id": "ldqbTPnDu1Zi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "US3LBxCf3BCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NXfcAeUj2_Y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nvidia-smi\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T18:01:16.569459Z",
          "iopub.execute_input": "2024-07-02T18:01:16.569902Z",
          "iopub.status.idle": "2024-07-02T18:01:17.664325Z",
          "shell.execute_reply.started": "2024-07-02T18:01:16.569865Z",
          "shell.execute_reply": "2024-07-02T18:01:17.663354Z"
        },
        "trusted": true,
        "id": "HHcO2Z00u1Zi",
        "outputId": "a4d6da9b-d416-4e91-c316-66d7ddf33156",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jul  2 18:40:20 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8               9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "\n",
        "\n",
        "# TensorFlow TPU/GPU Setup\n",
        "try:\n",
        "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(resolver)\n",
        "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "    strategy = tf.distribute.TPUStrategy(resolver)\n",
        "    print(\"Running on TPU:\", resolver.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "    strategy = tf.distribute.get_strategy()  # Default strategy for CPU and single GPU\n",
        "    print(\"Running on CPU/GPU\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T18:01:23.570276Z",
          "iopub.execute_input": "2024-07-02T18:01:23.571087Z",
          "iopub.status.idle": "2024-07-02T18:01:23.610206Z",
          "shell.execute_reply.started": "2024-07-02T18:01:23.571049Z",
          "shell.execute_reply": "2024-07-02T18:01:23.609297Z"
        },
        "trusted": true,
        "id": "fcEYQcdiu1Zi",
        "outputId": "373998f6-5e42-4156-b4b4-dffd66ba4c27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on CPU/GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T18:01:26.847277Z",
          "iopub.execute_input": "2024-07-02T18:01:26.84802Z",
          "iopub.status.idle": "2024-07-02T18:01:26.865128Z",
          "shell.execute_reply.started": "2024-07-02T18:01:26.847982Z",
          "shell.execute_reply": "2024-07-02T18:01:26.864165Z"
        },
        "trusted": true,
        "id": "FsE2jzu6u1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***MODULE-1***"
      ],
      "metadata": {
        "id": "vZTzwJF-u1Zi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOADING DATASET**"
      ],
      "metadata": {
        "id": "rgf5rzKnu1Zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the dataset from Kaggle input path\n",
        "file_path = \"/kaggle/input/cb-en-p2aie22006-manojvs/X-IIoTID dataset.csv\"\n",
        "# Read the dataset using cuDF\n",
        "xiom1 = cudf.read_csv(file_path)\n",
        "print(\"cuDF successfully loaded the dataset!\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T18:01:30.329665Z",
          "iopub.execute_input": "2024-07-02T18:01:30.330008Z",
          "iopub.status.idle": "2024-07-02T18:01:35.868182Z",
          "shell.execute_reply.started": "2024-07-02T18:01:30.329982Z",
          "shell.execute_reply": "2024-07-02T18:01:35.866784Z"
        },
        "trusted": true,
        "id": "m1PIE24eu1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EXPLORAORY DATA ANALYSIS (EDA)**"
      ],
      "metadata": {
        "id": "oAmK3EDMu1Zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary columns\n",
        "xiom1 = xiom1.drop(columns=['Timestamp', 'Date', 'class2', 'class3'])\n",
        "print(xiom1.shape)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T18:01:38.716439Z",
          "iopub.execute_input": "2024-07-02T18:01:38.716791Z",
          "iopub.status.idle": "2024-07-02T18:01:38.736169Z",
          "shell.execute_reply.started": "2024-07-02T18:01:38.716767Z",
          "shell.execute_reply": "2024-07-02T18:01:38.735359Z"
        },
        "trusted": true,
        "id": "pbxXNwiVu1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get string columns\n",
        "string_columns = xiom1.select_dtypes(include='object').columns\n",
        "\n",
        "print(\"\\nString Columns:\")\n",
        "print(list(string_columns))  # Convert to list directly for printing\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T18:01:41.569905Z",
          "iopub.execute_input": "2024-07-02T18:01:41.570621Z",
          "iopub.status.idle": "2024-07-02T18:01:41.583556Z",
          "shell.execute_reply.started": "2024-07-02T18:01:41.570589Z",
          "shell.execute_reply": "2024-07-02T18:01:41.582362Z"
        },
        "trusted": true,
        "id": "k0cFYFH4u1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nAll Columns:\")\n",
        "print(list(xiom1.columns))  # Convert to list directly for printing\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T18:01:43.732715Z",
          "iopub.execute_input": "2024-07-02T18:01:43.733615Z",
          "iopub.status.idle": "2024-07-02T18:01:43.738552Z",
          "shell.execute_reply.started": "2024-07-02T18:01:43.733581Z",
          "shell.execute_reply": "2024-07-02T18:01:43.737558Z"
        },
        "trusted": true,
        "id": "izl6uwgnu1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cudf\n",
        "\n",
        "# Assuming you have a cuDF DataFrame called `xiom1`\n",
        "# ... (your existing code)\n",
        "\n",
        "# Count of string columns\n",
        "num_string_cols = xiom1.select_dtypes(include='object').shape[1]\n",
        "print(\"Count of string columns:\", num_string_cols)\n",
        "\n",
        "# Count of all columns\n",
        "num_all_cols = len(xiom1.columns)\n",
        "print(\"Count of all columns:\", num_all_cols)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T18:01:45.957451Z",
          "iopub.execute_input": "2024-07-02T18:01:45.957814Z",
          "iopub.status.idle": "2024-07-02T18:01:45.96849Z",
          "shell.execute_reply.started": "2024-07-02T18:01:45.957786Z",
          "shell.execute_reply": "2024-07-02T18:01:45.967298Z"
        },
        "trusted": true,
        "id": "2wLB58g7u1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count of numeric columns (excluding boolean)\n",
        "numeric_columns = xiom1.select_dtypes(include=['int8', 'int16', 'int32', 'int64', 'float32', 'float64']).columns\n",
        "print(\"\\nNumeric Columns:\")\n",
        "print(list(numeric_columns))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T18:01:52.07021Z",
          "iopub.execute_input": "2024-07-02T18:01:52.071111Z",
          "iopub.status.idle": "2024-07-02T18:01:52.080992Z",
          "shell.execute_reply.started": "2024-07-02T18:01:52.071079Z",
          "shell.execute_reply": "2024-07-02T18:01:52.079829Z"
        },
        "trusted": true,
        "id": "Md54ikRPu1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count of numeric columns (excluding boolean)\n",
        "num_numeric_cols = len(numeric_columns)\n",
        "print(\"Count of numeric columns:\", num_numeric_cols)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T18:01:54.820115Z",
          "iopub.execute_input": "2024-07-02T18:01:54.820517Z",
          "iopub.status.idle": "2024-07-02T18:01:54.826179Z",
          "shell.execute_reply.started": "2024-07-02T18:01:54.820486Z",
          "shell.execute_reply": "2024-07-02T18:01:54.825169Z"
        },
        "trusted": true,
        "id": "AikcQMzJu1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Value Counts Before Filtering , class_counts ---> cc , class_counts_df -->cc_df\n",
        "cc = xiom1['class1'].value_counts()\n",
        "print(\"\\nValue counts for each class label in Class1:\")\n",
        "cc_df = cc.reset_index()\n",
        "cc_df.columns = [\"Class\", \"Count\"]\n",
        "print(cc_df.to_pandas().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T18:02:40.129556Z",
          "iopub.execute_input": "2024-07-02T18:02:40.130445Z",
          "iopub.status.idle": "2024-07-02T18:02:40.307197Z",
          "shell.execute_reply.started": "2024-07-02T18:02:40.130413Z",
          "shell.execute_reply": "2024-07-02T18:02:40.306159Z"
        },
        "trusted": true,
        "id": "dwGKV1-Eu1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Threshold for Removing Low Sample Attacks\n",
        "threshold = 0.005 * cc.max()\n",
        "\n",
        "# Filter classes that meet the threshold , filtered_counts ---> f_c\n",
        "f_c = cc[cc >= threshold]\n",
        "print(f\"\\nFiltered classes with counts above {threshold}:\")\n",
        "print(f_c.to_pandas().to_markdown(numalign=\"left\", stralign=\"left\"))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T18:02:43.177106Z",
          "iopub.execute_input": "2024-07-02T18:02:43.177517Z",
          "iopub.status.idle": "2024-07-02T18:02:43.230461Z",
          "shell.execute_reply.started": "2024-07-02T18:02:43.177485Z",
          "shell.execute_reply": "2024-07-02T18:02:43.229528Z"
        },
        "trusted": true,
        "id": "XxGCl_qZu1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the original DataFrame based on filtered_counts\n",
        "xiom1_flt = xiom1[xiom1['class1'].isin(f_c.index)]\n",
        "print(xiom1_flt.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T18:02:45.955546Z",
          "iopub.execute_input": "2024-07-02T18:02:45.956217Z",
          "iopub.status.idle": "2024-07-02T18:02:46.055024Z",
          "shell.execute_reply.started": "2024-07-02T18:02:45.956187Z",
          "shell.execute_reply": "2024-07-02T18:02:46.054098Z"
        },
        "trusted": true,
        "id": "7GzgGtvhu1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recalculate Value Counts After Filtering class_counts_filtered ---> ccf ,class_counts_filtered_to_pandas ---> ccf_pd\n",
        "ccf = xiom1_flt['class1'].value_counts()\n",
        "print(\"\\nValue counts for each filtered class label in Class1:\")\n",
        "ccf_pd = ccf.reset_index()\n",
        "ccf_pd.columns = [\"Class\", \"Count\"]\n",
        "print(ccf_pd.to_pandas().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T18:02:49.204847Z",
          "iopub.execute_input": "2024-07-02T18:02:49.205775Z",
          "iopub.status.idle": "2024-07-02T18:02:49.241051Z",
          "shell.execute_reply.started": "2024-07-02T18:02:49.205736Z",
          "shell.execute_reply": "2024-07-02T18:02:49.239949Z"
        },
        "trusted": true,
        "id": "rY9UAhVUu1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREPROCESSING**\n",
        "\n",
        "> ***1. LABEL ENCODING***"
      ],
      "metadata": {
        "id": "LoSSzO4_u1Zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert cuDF StringColumn to a list before encoding , string_labels ---> s_lb\n",
        "s_lb = xiom1_flt['class1'].to_arrow().to_pylist()\n",
        "LE = LabelEncoder()\n",
        "y_flt = LE.fit_transform(s_lb)  # Extract values directly\n",
        "# print(s_lb)\n",
        "# print_class_counts(pd.DataFrame(s_lb, columns=['class1']).groupby('class1').size().reset_index(name='Count'), verbose=8)  # Show top 8 labels\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T18:02:51.789451Z",
          "iopub.execute_input": "2024-07-02T18:02:51.79013Z",
          "iopub.status.idle": "2024-07-02T18:02:53.806251Z",
          "shell.execute_reply.started": "2024-07-02T18:02:51.790099Z",
          "shell.execute_reply": "2024-07-02T18:02:53.80526Z"
        },
        "trusted": true,
        "id": "NDQbsXKyu1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (Your previous imports, data loading, etc.)\n",
        "\n",
        "def print_class_counts(data, LE=None, verbose=5):\n",
        "    \"\"\"Prints a limited number of class labels and their counts in a table.\n",
        "\n",
        "    Args:\n",
        "        data: Data to be displayed (Series, cuDF, or Pandas DataFrame).\n",
        "        LE: LabelEncoder object (optional, used if labels are numeric).\n",
        "        verbose (int): Number of top labels to display (default: 5).\n",
        "    \"\"\"\n",
        "    print(f\"\\nCounts of Samples per Class (Top {verbose}):\")\n",
        "\n",
        "    # Convert series to dataframe if needed\n",
        "    if isinstance(data, cudf.Series):\n",
        "        data = data.reset_index(name=\"Count\")\n",
        "    elif isinstance(data, pd.Series):\n",
        "        data = data.reset_index(name=\"Count\")\n",
        "\n",
        "    # Convert labels back to original class names if they are encoded\n",
        "    if LE is not None and data.iloc[:, 0].dtype == 'int64':\n",
        "        data.iloc[:, 0] = LE.inverse_transform(data.iloc[:, 0].tolist())\n",
        "\n",
        "    # Convert to Pandas DataFrame if needed\n",
        "    if isinstance(data, cudf.DataFrame):\n",
        "        data = data.to_pandas()\n",
        "\n",
        "    # Renaming the columns ONLY when the data has only one column (from cudf Series conversion)\n",
        "    if(len(data.columns) == 1):\n",
        "        data.columns = [\"Class\", \"Count\"]\n",
        "\n",
        "    # Display the DataFrame (Top verbose classes)\n",
        "    display(data.head(verbose))\n",
        "\n",
        "# ... (Previous code for LE, s_lb remains the same)\n",
        "\n",
        "# Display the s_lb label counts\n",
        "print_class_counts(cudf.Series(s_lb).value_counts(), verbose=8)  # Convert s_lb to Series and display counts\n",
        "\n",
        "# # Apply Threshold for Removing Low Sample Attacks\n",
        "# threshold = 0.005 * cc.max()\n",
        "# f_c = cc[cc >= threshold]\n",
        "\n",
        "print(f\"\\nFiltered classes with counts above {threshold}:\")\n",
        "\n",
        "# Directly display filtered class counts\n",
        "print_class_counts(f_c, verbose=15)  # Use verbose to limit output\n",
        "\n",
        "\n",
        "# Display ONLY the filtered class counts using ccf\n",
        "print_class_counts(xiom1_flt['class1'].value_counts(), LE, verbose=15)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T18:02:57.115266Z",
          "iopub.execute_input": "2024-07-02T18:02:57.116182Z",
          "iopub.status.idle": "2024-07-02T18:02:57.249195Z",
          "shell.execute_reply.started": "2024-07-02T18:02:57.116143Z",
          "shell.execute_reply": "2024-07-02T18:02:57.248154Z"
        },
        "trusted": true,
        "id": "gO2V8zvCu1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ***2 .One hot encoding***"
      ],
      "metadata": {
        "id": "tRXiDAIwu1Zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encode Categorical Features (excluding class1) - Using GPU\n",
        "OHE = OneHotEncoder()\n",
        "X_flt = OHE.fit_transform(xiom1_flt.drop(columns=['class1']))  # cuDF DataFrame remains in GPU\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T18:03:01.1913Z",
          "iopub.execute_input": "2024-07-02T18:03:01.192263Z",
          "iopub.status.idle": "2024-07-02T18:03:09.091307Z",
          "shell.execute_reply.started": "2024-07-02T18:03:01.192222Z",
          "shell.execute_reply": "2024-07-02T18:03:09.090379Z"
        },
        "trusted": true,
        "id": "0u_Jw4qOu1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (Your code for importing, data loading, filtering, label encoding)\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from scipy.sparse import vstack  # For stacking sparse matrices vertically"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T18:03:13.92233Z",
          "iopub.execute_input": "2024-07-02T18:03:13.922978Z",
          "iopub.status.idle": "2024-07-02T18:03:13.927177Z",
          "shell.execute_reply.started": "2024-07-02T18:03:13.922948Z",
          "shell.execute_reply": "2024-07-02T18:03:13.926204Z"
        },
        "trusted": true,
        "id": "dro6o9Vfu1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (Your code for importing, data loading, filtering, label encoding)\n",
        "\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from scipy.sparse import vstack, coo_matrix\n",
        "\n",
        "# ... (Rest of your code)\n",
        "\n",
        "# Resampling (ADASYN):\n",
        "# Resample with ADASYN DIRECTLY on the Sparse matrix in smaller chunks\n",
        "\n",
        "# Determine chunk size dynamically based on available memory and sample size\n",
        "chunk_size = xiom1_flt.shape[0] // 10  # Process in 10 chunks\n",
        "\n",
        "X_res_chunks = []\n",
        "y_res_chunks = []\n",
        "\n",
        "for i in range(0, xiom1_flt.shape[0], chunk_size):  # Use the full shape of xiom1_flt\n",
        "\n",
        "    # Determine the start and end indices of the chunk\n",
        "    start = i  # Correct starting index\n",
        "    end = start + chunk_size\n",
        "\n",
        "    # Use boolean indexing with CuPy arrays\n",
        "    X_coo = X_flt.tocoo()\n",
        "    chunk_rows_mask = (X_coo.row >= start) & (X_coo.row < end)\n",
        "\n",
        "    chunk_data = X_coo.data[chunk_rows_mask]\n",
        "    chunk_rows = X_coo.row[chunk_rows_mask] - start  # Adjust row indices to local chunk\n",
        "    chunk_cols = X_coo.col[chunk_rows_mask]\n",
        "\n",
        "\n",
        "    # Construct X_chunk_coo from the subset data\n",
        "    X_chunk_coo = coo_matrix((chunk_data.get(), (chunk_rows.get(), chunk_cols.get())))\n",
        "\n",
        "    # Get the corresponding labels for this chunk\n",
        "    y_chunk = y_flt[start:end]\n",
        "\n",
        "    # Apply ADASYN directly on the sparse matrix\n",
        "    adasyn = ADASYN(random_state=42)\n",
        "    X_res_chunk_coo, y_res_chunk = adasyn.fit_resample(X_chunk_coo, y_chunk)\n",
        "\n",
        "    X_res_chunks.append(X_res_chunk_coo)\n",
        "    y_res_chunks.append(y_res_chunk)\n",
        "\n",
        "# Combine the resampled chunks sparse matrices\n",
        "X_res_coo = vstack(X_res_chunks)\n",
        "y_res = np.concatenate(y_res_chunks)\n",
        "\n",
        "# Now convert X_res back to cuDF (from sparse COO)\n",
        "X_res = cudf.DataFrame.sparse.from_scipy(X_res_coo)\n",
        "\n",
        "# Split Data (Note that we are splitting the oversampled data now)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "print(f\"X_train.shape: {X_train.shape}, y_train.shape: {y_train.shape}\")\n",
        "print(f\"X_val.shape: {X_val.shape}, y_val.shape: {y_val.shape}\")\n",
        "print(f\"X_test.shape: {X_test.shape}, y_test.shape: {y_test.shape}\")\n",
        "\n",
        "# ... (Rest of your code: scaling, printing, saving data)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-02T18:03:19.280196Z",
          "iopub.execute_input": "2024-07-02T18:03:19.280923Z"
        },
        "trusted": true,
        "id": "tNVZZ3iCu1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# # Split Data\n",
        "# X_train, X_temp, y_train, y_temp = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "# X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# # Feature Scaling (MinMaxScaler)\n",
        "# scaler = MinMaxScaler()\n",
        "# X_train_scaled = scaler.fit_transform(X_train.to_pandas())\n",
        "# X_val_scaled = scaler.transform(X_val.to_pandas())\n",
        "# X_test_scaled = scaler.transform(X_test.to_pandas())\n",
        "\n",
        "# # Convert back to cudf Dataframes\n",
        "# X_train_scaled = cudf.DataFrame(X_train_scaled)\n",
        "# X_val_scaled = cudf.DataFrame(X_val_scaled)\n",
        "# X_test_scaled = cudf.DataFrame(X_test_scaled)\n",
        "\n",
        "# # Create Directories to Save Datasets\n",
        "# base_dir = \"/kaggle/working/cb-en-p2aie22006\"\n",
        "# os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# train_dir = os.path.join(base_dir, \"train_data\")\n",
        "# val_dir = os.path.join(base_dir, \"val_data\")\n",
        "# test_dir = os.path.join(base_dir, \"test_data\")\n",
        "# os.makedirs(train_dir, exist_ok=True)\n",
        "# os.makedirs(val_dir, exist_ok=True)\n",
        "# os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# # Save Train, Validation, and Test Data\n",
        "# X_train_scaled.to_csv(os.path.join(train_dir, \"train_features.csv\"), index=False)\n",
        "# np.savetxt(os.path.join(train_dir, \"train_labels.csv\"), y_train, delimiter=\",\")\n",
        "\n",
        "# X_val_scaled.to_csv(os.path.join(val_dir, \"val_features.csv\"), index=False)\n",
        "# np.savetxt(os.path.join(val_dir, \"val_labels.csv\"), y_val, delimiter=\",\")\n",
        "\n",
        "# X_test_scaled.to_csv(os.path.join(test_dir, \"test_features.csv\"), index=False)\n",
        "# np.savetxt(os.path.join(test_dir, \"test_labels.csv\"), y_test, delimiter=\",\")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "N14aNB5zu1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D\n",
        "# from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoarddef create_cnn_model(input_shape):\n",
        "#     model = Sequential([\n",
        "#         Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "#         MaxPooling1D(pool_size=2),\n",
        "#         Flatten(),\n",
        "#         Dense(128, activation='relu'),\n",
        "#         Dropout(0.5),\n",
        "#         Dense(64, activation='relu'),\n",
        "#         Dropout(0.5),\n",
        "#         Dense(1, activation='sigmoid')  # Binary classification\n",
        "#     ])\n",
        "#     return model\n",
        "\n",
        "# # Create and train the base model\n",
        "# with strategy.scope():\n",
        "#     model = create_cnn_model(input_shape=(X_train_union.shape[1], 1))\n",
        "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#     model_checkpoint = ModelCheckpoint(\n",
        "#         filepath=\"/kaggle/working/best_model_dl.h5\",\n",
        "#         save_best_only=True,\n",
        "#         monitor=\"val_accuracy\",\n",
        "#         mode=\"max\",\n",
        "#         verbose=1\n",
        "#     )\n",
        "\n",
        "#     model.fit(\n",
        "#         X_train_union.to_pandas(), y_train, epochs=10, batch_size=32,\n",
        "#         validation_data=(X_val_union.to_pandas(), y_val), callbacks=[model_checkpoint, tensorboard_callback]\n",
        "#     )\n",
        "#     best_model_dl = load_model(\"/kaggle/working/best_model_dl.h5\")\n",
        "\n",
        "#     # Transfer Learning Model (VGG16) - (Trained on X_train_union)\n",
        "#     # Reshape for VGG16 (assuming 128x128 input)\n",
        "#     X_train_union_reshaped = X_train_union.to_pandas().to_numpy()\n",
        "#     X_train_union_reshaped = tf.image.resize(X_train_union_reshaped, [128, 128])\n",
        "#     X_train_union_reshaped = tf.repeat(X_train_union_reshaped[..., np.newaxis], 3, -1)\n",
        "#     X_val_union_reshaped = X_val_union.to_pandas().to_numpy()\n",
        "#     X_val_union_reshaped = tf.image.resize(X_val_union_reshaped, [128, 128])\n",
        "#     X_val_union_reshaped = tf.repeat(X_val_union_reshaped[..., np.newaxis], 3, -1)\n",
        "\n",
        "#     # Load pre-trained model (VGG16) for transfer learning\n",
        "#     base_model = tf.keras.applications.VGG16(\n",
        "#         weights='imagenet', include_top=False, input_shape=(128, 128, 3)\n",
        "#     )\n",
        "#     base_model.trainable = False\n",
        "\n",
        "#     # Flatten the output of the base model\n",
        "#     x = Flatten()(base_model.output)\n",
        "\n",
        "#     # Add new classifier layers on top of the base model\n",
        "#     x = Dense(256, activation='relu')(x)\n",
        "#     x = Dropout(0.5)(x)\n",
        "#     predictions = Dense(1, activation='sigmoid')(x)  # Binary classification\n",
        "\n",
        "#     # Create the transfer learning model\n",
        "#     model_transfer = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "#     model_transfer.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#     model_transfer_history = model_transfer.fit(\n",
        "#         X_train_union_reshaped, y_train, epochs=10, batch_size=32,\n",
        "#         validation_data=(X_val_union_reshaped, y_val)\n",
        "#     )\n",
        "\n",
        "\n",
        "\n",
        "# # Evaluate All Models\n",
        "# models = models_union + models_rl + [best_model_dl, model_transfer]\n",
        "# model_names = model_names_union + model_names_rl + ['Deep Learning (Basic)', 'Deep Learning (Transfer)']\n",
        "\n",
        "# specific_attacks = ['C&C', 'Modbus/TCP', 'DoS']\n",
        "\n",
        "# for i, model in enumerate(models):\n",
        "#     if isinstance(model, Sequential):  # Check if it's a deep learning model\n",
        "#         X_test_np = X_test_union.to_numpy()\n",
        "#         evaluate_and_plot(model, X_test_np, y_test, model_names[i], specific_attacks)  # Evaluate on test data\n",
        "#     else:\n",
        "#         if \"RL\" in model_names[i]:\n",
        "#             X_test_df = X_test_reduced_rl.to_pandas()\n",
        "#         else:\n",
        "#             X_test_df = X_test_union.to_pandas()\n",
        "#         evaluate_and_plot(model, X_test_df, y_test, model_names[i], specific_attacks)  # Evaluate on test data\n",
        "\n",
        "\n",
        "# # 8. Additional Analysis (Best Model Selection and Final Evaluation)\n",
        "# # ------------------------------------------------------------------\n",
        "\n",
        "# # Lists to store all models and their names (union, rl, and DL)\n",
        "# all_models = models_union + models_rl\n",
        "# all_model_names = model_names_union + model_names_rl\n",
        "# all_x_values = [X_val_union.to_pandas()] * 3 + [X_val_reduced_rl.to_pandas()] * 3\n",
        "\n",
        "\n",
        "# all_model_accuracies = [\n",
        "#     grid_search_rf.best_score_,\n",
        "#     grid_search_et.best_score_,\n",
        "#     voting_clf_union.score(X_val_union.to_pandas(), y_val),\n",
        "#     max(model_history.history['val_accuracy']),\n",
        "#     max(model_transfer_history.history['val_accuracy']),\n",
        "#     grid_search_rf_rl.best_score_,\n",
        "#     grid_search_et_rl.best_score_,\n",
        "#     voting_clf_rl.score(X_val_reduced_rl.to_pandas(), y_val) # Convert to pandas\n",
        "# ]\n",
        "\n",
        "# best_model_idx = np.argmax(all_model_accuracies)\n",
        "# best_model = models[best_model_idx]\n",
        "# best_model_name = model_names[best_model_idx]\n",
        "\n",
        "# print(f\"\\nBest Model based on Validation Accuracy: {best_model_name}\")\n",
        "# print(f\"\\nBest Model's Validation Accuracy: {np.max(all_model_accuracies)}\")\n",
        "# print(f\"\\nBest Model's Test Accuracy: {all_model_accuracies[best_model_idx]}\")\n",
        "\n",
        "\n",
        "# # dyn_mjpu5.py (Final Evaluation and Model Saving)\n",
        "# # ... (Previous code for model training and evaluation)\n",
        "\n",
        "# # Final Evaluation on Test Set\n",
        "# if best_model_name in ['Deep Learning (Basic)', 'Deep Learning (Transfer)']:\n",
        "#     y_pred_best = (best_model.predict(X_test_union_np) > 0.5).astype(int)\n",
        "# else:\n",
        "#     X_test_best = (\n",
        "#         X_test_scaled if best_model_idx < 3 else X_test_reduced_rl\n",
        "#     )  # Choose the right test set based on the best model\n",
        "#     y_pred_best = best_model.predict(X_test_best.to_pandas())\n",
        "\n",
        "# print(f\"\\nFinal Test Set Classification Report ({best_model_name}):\\n\", classification_report(y_test, y_pred_best, target_names=le.classes_))\n",
        "\n",
        "# # Print best parameters for all models (union and RL)\n",
        "# print(f\"\\nBest Random Forest Parameters: {grid_search_rf.best_params_}\")\n",
        "# print(f\"\\nBest Extra Trees Parameters: {grid_search_et.best_params_}\")\n",
        "# print(f\"\\nBest Random Forest (RL) Parameters: {grid_search_rf_rl.best_params_}\")\n",
        "# print(f\"\\nBest Extra Trees (RL) Parameters: {grid_search_et_rl.best_params_}\")\n",
        "\n",
        "\n",
        "# # Save the best model to Kaggle Output\n",
        "# if isinstance(best_model, Sequential):\n",
        "#     best_model.save(\"best_model.h5\")\n",
        "# else:\n",
        "#     import joblib\n",
        "#     joblib.dump(best_model, 'best_model.pkl')\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "1dHsaP3hu1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # dyn_mjpu5_pt4.py (Deep Learning and Final Evaluation)\n",
        "# # ... (all imports from dyn_mjpu5_pt1.py and dyn_mjpu5_pt2.py)\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D\n",
        "# from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "\n",
        "\n",
        "# # 7. Deep Learning Model Training and Evaluation on Test Data\n",
        "# # ------------------------------------------------------------\n",
        "\n",
        "# # Define deep learning models with transfer learning and without\n",
        "# def create_cnn_model(input_shape):\n",
        "#     model = Sequential([\n",
        "#         Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "#         MaxPooling1D(pool_size=2),\n",
        "#         Flatten(),\n",
        "#         Dense(128, activation='relu'),\n",
        "#         Dropout(0.5),\n",
        "#         Dense(64, activation='relu'),\n",
        "#         Dropout(0.5),\n",
        "#         Dense(1, activation='sigmoid')  # Binary classification\n",
        "#     ])\n",
        "#     return model\n",
        "\n",
        "# # Create and train the base model\n",
        "# with strategy.scope():\n",
        "#     model = create_cnn_model(input_shape=(X_train_scaled.shape[1], 1))\n",
        "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#     # ModelCheckpoint callback to save the best model based on validation accuracy\n",
        "#     model_checkpoint = ModelCheckpoint(\n",
        "#         filepath=\"/kaggle/working/best_model_dl.h5\",\n",
        "#         save_best_only=True,\n",
        "#         monitor=\"val_accuracy\",\n",
        "#         mode=\"max\",\n",
        "#         verbose=1\n",
        "#     )\n",
        "\n",
        "#     model.fit(\n",
        "#         X_train_scaled.to_pandas(), y_train, epochs=10, batch_size=32,\n",
        "#         validation_data=(X_val_scaled.to_pandas(), y_val), callbacks=[model_checkpoint, tensorboard_callback]\n",
        "#     )\n",
        "#     best_model_dl = load_model(\"/kaggle/working/best_model_dl.h5\")\n",
        "\n",
        "#     # Transfer Learning Model (VGG16) - (Trained on X_train_union)\n",
        "#     # Reshape for VGG16 (assuming 128x128 input)\n",
        "#     X_train_union_reshaped = X_train_union.to_pandas().to_numpy()\n",
        "#     X_train_union_reshaped = tf.image.resize(X_train_union_reshaped, [128, 128])\n",
        "#     X_train_union_reshaped = tf.repeat(X_train_union_reshaped[..., np.newaxis], 3, -1)\n",
        "#     X_val_union_reshaped = X_val_union.to_pandas().to_numpy()\n",
        "#     X_val_union_reshaped = tf.image.resize(X_val_union_reshaped, [128, 128])\n",
        "#     X_val_union_reshaped = tf.repeat(X_val_union_reshaped[..., np.newaxis], 3, -1)\n",
        "\n",
        "#     # Load pre-trained VGG16 model\n",
        "#     base_model = tf.keras.applications.VGG16(\n",
        "#         weights='imagenet', include_top=False, input_shape=(128, 128, 3)\n",
        "#     )\n",
        "#     base_model.trainable = False  # Freeze base model layers\n",
        "\n",
        "#     model_transfer = Sequential([\n",
        "#         base_model,\n",
        "#         Flatten(),\n",
        "#         Dense(256, activation='relu'),\n",
        "#         Dropout(0.5),\n",
        "#         Dense(128, activation='relu'),\n",
        "#         Dropout(0.5),\n",
        "#         Dense(1, activation='sigmoid')  # Binary classification\n",
        "#     ])\n",
        "\n",
        "#     model_transfer.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#     model_transfer_history = model_transfer.fit(\n",
        "#         X_train_union_reshaped, y_train, epochs=10, batch_size=32,\n",
        "#         validation_data=(X_val_union_reshaped, y_val)\n",
        "#     )\n",
        "\n",
        "\n",
        "\n",
        "# # 7. Evaluate All Models on the Test Set\n",
        "# models = models_union + models_rl + [best_model_dl, model_transfer]\n",
        "# model_names = model_names_union + model_names_rl + ['Deep Learning (Basic)', 'Deep Learning (Transfer)']\n",
        "\n",
        "# specific_attacks = ['C&C', 'Modbus/TCP', 'DoS']\n",
        "\n",
        "# for i, model in enumerate(models):\n",
        "#     if isinstance(model, Sequential):  # Check if it's a deep learning model\n",
        "#         X_test_np = X_test_scaled.to_numpy()\n",
        "#         evaluate_and_plot(model, X_test_np, y_test, model_names[i], specific_attacks)  # Evaluate on test data\n",
        "#     else:\n",
        "#         if \"RL\" in model_names[i]:\n",
        "#             X_test_df = X_test_reduced_rl.to_pandas()\n",
        "#         else:\n",
        "#             X_test_df = X_test_union.to_pandas()\n",
        "#         evaluate_and_plot(model, X_test_df, y_test, model_names[i], specific_attacks)  # Evaluate on test data\n",
        "\n",
        "\n",
        "# # 8. Additional Analysis (Best Model Selection and Final Evaluation)\n",
        "# # ------------------------------------------------------------------\n",
        "# all_model_accuracies = [\n",
        "#     grid_search_rf.best_score_,\n",
        "#     grid_search_et.best_score_,\n",
        "#     voting_clf_union.score(X_val_union.to_pandas(), y_val),\n",
        "#     max(model_history.history['val_accuracy']),\n",
        "#     max(model_transfer_history.history['val_accuracy']),\n",
        "#     grid_search_rf_rl.best_score_,\n",
        "#     grid_search_et_rl.best_score_,\n",
        "#     voting_clf_rl.score(X_val_reduced_rl.to_pandas(), y_val) # Convert to pandas\n",
        "# ]\n",
        "\n",
        "# best_model_idx = np.argmax(all_model_accuracies)\n",
        "# best_model = models[best_model_idx]\n",
        "# best_model_name = model_names[best_model_idx]\n",
        "\n",
        "# print(f\"\\nBest Model based on Validation Accuracy: {best_model_name}\")\n",
        "# print(f\"\\nBest Model's Validation Accuracy: {np.max(all_model_accuracies)}\")\n",
        "# print(f\"\\nBest Model's Test Accuracy: {all_model_accuracies[best_model_idx]}\")\n",
        "\n",
        "\n",
        "# # Final Evaluation on Test Set\n",
        "# if best_model_name in ['Deep Learning (Basic)', 'Deep Learning (Transfer)']:\n",
        "#     y_pred_best = (best_model.predict(X_test_scaled.to_numpy()) > 0.5).astype(int)\n",
        "# else:\n",
        "#     X_test_best = (\n",
        "#         X_test_scaled if best_model_idx < 3 else X_test_reduced_rl\n",
        "#     )  # Choose the right test set based on the best model\n",
        "#     y_pred_best = best_model.predict(X_test_best.to_pandas())\n",
        "\n",
        "# print(f\"\\nFinal Test Set Classification Report ({best_model_name}):\\n\", classification_report(y_test, y_pred_best, target_names=le.classes_))\n",
        "\n",
        "# # Print best parameters for Random Forest and Extra Trees models\n",
        "# print(f\"\\nBest Random Forest Parameters: {grid_search_rf.best_params_}\")\n",
        "# print(f\"\\nBest Extra Trees Parameters: {grid_search_et.best_params_}\")\n",
        "# print(f\"\\nBest Random Forest (RL features) Parameters: {grid_search_rf_rl.best_params_}\")\n",
        "# print(f\"\\nBest Extra Trees (RL features) Parameters: {grid_search_et_rl.best_params_}\")\n",
        "\n",
        "# # Save the best model to Kaggle Output\n",
        "# if isinstance(best_model, Sequential):\n",
        "#     best_model.save(\"best_model.h5\")\n",
        "# else:\n",
        "#     joblib.dump(best_model, 'best_model.pkl')\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "4hoSofcIu1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#     #dynxpu_skl8\n",
        "#     import cudf\n",
        "#     import pandas as pd\n",
        "#     import numpy as np\n",
        "#     import matplotlib.pyplot as plt\n",
        "#     import seaborn as sns\n",
        "#     import os\n",
        "#     import joblib  # For saving scikit-learn models\n",
        "\n",
        "#     from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "#     from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "#     from imblearn.over_sampling import ADASYN\n",
        "#     from sklearn.ensemble import VotingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
        "#     from sklearn.metrics import (\n",
        "#         classification_report, confusion_matrix, make_scorer, matthews_corrcoef,\n",
        "#     )\n",
        "#     from datetime import datetime\n",
        "#     from stable_baselines3 import PPO\n",
        "#     import tensorflow as tf\n",
        "#     from tensorflow.keras.models import Sequential, load_model\n",
        "#     from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D\n",
        "#     from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "#     from cuml.preprocessing import OneHotEncoder\n",
        "#     from cuml.metrics import confusion_matrix\n",
        "\n",
        "#     # 1. Data Loading and Preprocessing\n",
        "#     # -----------------------------------\n",
        "#     # ... [Load the dataset using cuDF, drop unnecessary columns, calculate value counts, apply threshold (optional), and filter the dataset.]\n",
        "#     # ... [Perform Label Encoding and One-Hot Encode Categorical Features (excluding class1).]\n",
        "#     # ... [Resample the dataset using ADASYN, then Split Data into train, validation, and test sets.]\n",
        "\n",
        "#     # Feature Scaling (MinMaxScaler)\n",
        "#     try:\n",
        "#         # Use cuML's MinMaxScaler if available\n",
        "#         from cuml.preprocessing import MinMaxScaler as cuMMScaler\n",
        "#         scaler = cuMMScaler()\n",
        "#         X_train_scaled = scaler.fit_transform(X_train)\n",
        "#         X_val_scaled = scaler.transform(X_val)\n",
        "#         X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "#     except ImportError:\n",
        "#         # Fallback to scikit-learn's MinMaxScaler if cuML is not available\n",
        "#         from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#         scaler = MinMaxScaler()\n",
        "#         X_train_scaled = scaler.fit_transform(X_train.to_pandas())  # Convert to pandas\n",
        "#         X_val_scaled = scaler.transform(X_val.to_pandas())       # Convert to pandas\n",
        "#         X_test_scaled = scaler.transform(X_test.to_pandas())      # Convert to pandas\n",
        "#         X_train_scaled = cudf.DataFrame(X_train_scaled)\n",
        "#         X_val_scaled = cudf.DataFrame(X_val_scaled)\n",
        "#         X_test_scaled = cudf.DataFrame(X_test_scaled)\n",
        "\n",
        "\n",
        "#     # Create Directories to Save Datasets\n",
        "#     base_dir = \"/kaggle/working/cb-en-p2aie22006\"\n",
        "#     os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "#     train_dir = os.path.join(base_dir, \"train_data\")\n",
        "#     val_dir = os.path.join(base_dir, \"val_data\")\n",
        "#     test_dir = os.path.join(base_dir, \"test_data\")\n",
        "#     os.makedirs(train_dir, exist_ok=True)\n",
        "#     os.makedirs(val_dir, exist_ok=True)\n",
        "#     os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "#     # Save Train, Validation, and Test Data\n",
        "#     X_train_scaled.to_csv(os.path.join(train_dir, \"train_features.csv\"), index=False)\n",
        "#     np.savetxt(os.path.join(train_dir, \"train_labels.csv\"), y_train, delimiter=\",\")\n",
        "\n",
        "#     X_val_scaled.to_csv(os.path.join(val_dir, \"val_features.csv\"), index=False)\n",
        "#     np.savetxt(os.path.join(val_dir, \"val_labels.csv\"), y_val, delimiter=\",\")\n",
        "\n",
        "#     X_test_scaled.to_csv(os.path.join(test_dir, \"test_features.csv\"), index=False)\n",
        "#     np.savetxt(os.path.join(test_dir, \"test_labels.csv\"), y_test, delimiter=\",\")\n",
        "\n",
        "#     print(\"Completed scaling\")\n",
        "\n",
        "#     # 2. Function Definitions\n",
        "#     # -------------------------\n",
        "#     # ... (get_attack_labels and evaluate_and_plot functions remain the same as in the previous response)\n",
        "\n",
        "#     # 3. Machine Learning Model Training and Evaluation on Original Features\n",
        "#     # ----------------------------------------------------------------------\n",
        "#     # ... (Train and evaluate ML models on the original scaled features - Random Forest, Extra Trees, and Voting Classifier)\n",
        "#     # ... (Feature Selection based on Union of Top Features from RF and ET)\n",
        "\n",
        "#     # 4. Retrain and evaluate ML models on the union of features\n",
        "#     # ---------------------------------------------------------\n",
        "\n",
        "#     # ... (Retrain and evaluate ML models on the union of features - Random Forest, Extra Trees, and Voting Classifier)\n",
        "\n",
        "#     # 5. Reinforcement Learning-Based Feature Selection\n",
        "#     # ---------------------------------------------------\n",
        "\n",
        "#     # ... (Define FeatureSelectionEnv class)\n",
        "\n",
        "#     # ... (Set up RL environment, train RL model, get best features)\n",
        "\n",
        "#     # ... (Train and evaluate ML models on the RL-selected features)\n",
        "\n",
        "#     # 6. Deep Learning Model Training and Evaluation\n",
        "#     # -----------------------------------------------\n",
        "\n",
        "#     # ... (Define create_cnn_model function)\n",
        "\n",
        "#     with strategy.scope():\n",
        "#         # Basic Deep Learning Model (Trained on X_train_union)\n",
        "#         # ... (same as before)\n",
        "\n",
        "#         # Transfer Learning Model (VGG16) - (Trained on X_train_union)\n",
        "#         # ... (same as before)\n",
        "\n",
        "#     # 7. Evaluate All Models on the Test Set\n",
        "#     # ----------------------------------------\n",
        "\n",
        "#     # ... (Evaluate all models - ML and DL - on the test set)\n",
        "#     models = models_union + models_rl + [best_model_dl, model_transfer]\n",
        "#     model_names = model_names_union + model_names_rl + ['Deep Learning (Basic)', 'Deep Learning (Transfer)']\n",
        "\n",
        "#     specific_attacks = ['C&C', 'Modbus/TCP', 'DoS']\n",
        "\n",
        "#     for i, model in enumerate(models):\n",
        "#         if isinstance(model, Sequential):  # Check if it's a deep learning model\n",
        "#             X_test_np = X_test_union.to_numpy()\n",
        "#             evaluate_and_plot(model, X_test_np, y_test, model_names[i], specific_attacks)  # Evaluate on test data\n",
        "#         else:\n",
        "#             # Convert cuDF to pandas for scikit-learn models if needed\n",
        "#             if \"RL\" in model_names[i]:\n",
        "#                 X_test_df = X_test_reduced_rl.to_pandas()\n",
        "#             else:\n",
        "#                 X_test_df = X_test_union.to_pandas()\n",
        "#             evaluate_and_plot(model, X_test_df, y_test, model_names[i], specific_attacks)  # Evaluate on test data\n",
        "\n",
        "\n",
        "#     # 8. Additional Analysis (Best Model Selection and Final Evaluation)\n",
        "#     # ------------------------------------------------------------------\n",
        "#     all_model_accuracies = [\n",
        "#         grid_search_rf.best_score_,\n",
        "#         grid_search_et.best_score_,\n",
        "#         voting_clf_union.score(X_val_union.to_pandas(), y_val),\n",
        "#         max(model_history.history['val_accuracy']),\n",
        "#         max(model_transfer_history.history['val_accuracy']),\n",
        "#         grid_search_rf_rl.best_score_,\n",
        "#         grid_search_et_rl.best_score_,\n",
        "#         voting_clf_rl.score(X_val_reduced_rl.to_pandas(), y_val) # Convert to pandas\n",
        "#     ]\n",
        "\n",
        "#     best_model_idx = np.argmax(all_model_accuracies)\n",
        "#     best_model = models[best_model_idx]\n",
        "#     best_model_name = model_names[best_model_idx]\n",
        "\n",
        "#     print(f\"\\nBest Model based on Validation Accuracy: {best_model_name}\")\n",
        "#     print(f\"\\nBest Model's Validation Accuracy: {np.max(all_model_accuracies)}\")\n",
        "#     print(f\"\\nBest Model's Test Accuracy: {all_model_accuracies[best_model_idx]}\")\n",
        "\n",
        "#     # Final Evaluation on Test Set\n",
        "#     if best_model_name in ['Deep Learning (Basic)', 'Deep Learning (Transfer)']:\n",
        "#         y_pred_best = (best_model.predict(X_test_scaled.to_numpy()) > 0.5).astype(int)\n",
        "#     else:\n",
        "#         X_test_best = (\n",
        "#             X_test_scaled if best_model_idx < 3 else X_test_reduced_rl\n",
        "#         )  # Choose the right test set based on the best model\n",
        "#         y_pred_best = best_model.predict(X_test_best.to_pandas())\n",
        "\n",
        "#     print(f\"\\nFinal Test Set Classification Report ({best_model_name}):\\n\", classification_report(y_test, y_pred_best, target_names=le.classes_))\n",
        "\n",
        "#     # Print best parameters for all models (union and RL)\n",
        "#     # ... (same as before)\n",
        "\n",
        "#     # Save the best model to Kaggle Output\n",
        "#     if isinstance(best_model, Sequential):\n",
        "#         best_model.save(\"best_model.h5\")  # Save Keras/TF model\n",
        "#     else:\n",
        "#         joblib.dump(best_model, 'best_model.pkl')  # Save scikit-learn model"
      ],
      "metadata": {
        "trusted": true,
        "id": "mLlxGmHRu1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dyn_mjpu6_pt1\n",
        "# import cudf\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import os\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "# from imblearn.over_sampling import ADASYN\n",
        "# from cuml.preprocessing import OneHotEncoder\n",
        "# import warnings\n",
        "# # TensorFlow TPU/GPU Setup\n",
        "# try:\n",
        "#   resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "#   tf.config.experimental_connect_to_cluster(resolver)\n",
        "#   tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "#   strategy = tf.distribute.TPUStrategy(resolver)\n",
        "#   print(\"Running on TPU:\", resolver.cluster_spec().as_dict()['worker'])\n",
        "# except ValueError:\n",
        "#   strategy = tf.distribute.get_strategy() # Default strategy for CPU and single GPU\n",
        "#   print(\"Running on CPU/GPU\")\n",
        "\n",
        "\n",
        "# # Filter DeprecationWarnings to avoid cluttering output\n",
        "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# # Filter DtypeWarnings that might arise from mismatched data types\n",
        "# # (e.g., when converting between cuDF and Pandas)\n",
        "# warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# # 1. Data Loading and Preprocessing\n",
        "# # -----------------------------------\n",
        "\n",
        "# # Load the dataset from Kaggle input path\n",
        "# file_path = \"/kaggle/input/cb-en-p2aie22006-manojvs/X-IIoTID dataset.csv\"\n",
        "\n",
        "# # Read the dataset using cuDF\n",
        "# xiom1 = cudf.read_csv(file_path)\n",
        "# print(\"cuDF successfully loaded the dataset!\")\n",
        "\n",
        "# # Drop unnecessary columns\n",
        "# xiom1 = xiom1.drop(columns=['Timestamp', 'Date', 'class2', 'class3'])\n",
        "# print(xiom1.shape)\n",
        "\n",
        "# # Calculate Value Counts Before Filtering\n",
        "# class_counts = xiom1['class1'].value_counts()\n",
        "# print(\"\\nValue counts for each class label in Class1:\")\n",
        "# class_counts_df = class_counts.reset_index()\n",
        "# class_counts_df.columns = [\"Class\", \"Count\"]\n",
        "# print(class_counts_df.to_pandas().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "# # Apply Threshold for Removing Low Sample Attacks (optional)\n",
        "# threshold = 0.05 * class_counts.max()\n",
        "\n",
        "# # Filter classes that meet the threshold\n",
        "# filtered_counts = class_counts[class_counts >= threshold]\n",
        "# print(f\"\\nFiltered classes with counts above {threshold}:\")\n",
        "# print(filtered_counts.to_pandas().to_markdown(numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "# # Filter the original DataFrame based on filtered_counts\n",
        "# xiom1_filtered = xiom1[xiom1['class1'].isin(filtered_counts.index)]\n",
        "\n",
        "# # Recalculate Value Counts After Filtering\n",
        "# class_counts_filtered = xiom1_filtered['class1'].value_counts()\n",
        "# print(\"\\nValue counts for each filtered class label in Class1:\")\n",
        "# class_counts_filtered_df = class_counts_filtered.reset_index()\n",
        "# class_counts_filtered_df.columns = [\"Class\", \"Count\"]\n",
        "# print(class_counts_filtered_df.to_pandas().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "\n",
        "# # Label Encoding (include \"Normal\")\n",
        "# le = LabelEncoder()\n",
        "# y_filtered = le.fit_transform(xiom1_filtered['class1'].to_arrow().to_pylist())\n",
        "\n",
        "# # One-Hot Encode Categorical Features (excluding class1) - Using GPU\n",
        "# encoder = OneHotEncoder()\n",
        "# X_filtered = encoder.fit_transform(xiom1_filtered.drop(columns=['class1']))  # cuDF DataFrame remains in GPU\n",
        "\n",
        "# # Manually drop the first column to avoid multicollinearity\n",
        "# X_filtered = X_filtered.drop(X_filtered.columns[0])  # Correctly drop the first column using cuDF syntax\n",
        "\n",
        "# # Resampling (ADASYN):\n",
        "# adasyn = ADASYN(random_state=42)\n",
        "# X_resampled, y_resampled = adasyn.fit_resample(X_filtered.to_pandas(), y_filtered)  # Convert to pandas for compatibility\n",
        "# X_resampled = cudf.DataFrame(X_resampled)  # Convert back to cuDF\n",
        "\n",
        "# # Split Data\n",
        "# X_train, X_temp, y_train, y_temp = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "# X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "# print(f\"X_train.shape: {X_train.shape}, y_train.shape: {y_train.shape}\")\n",
        "# print(f\"X_val.shape: {X_val.shape}, y_val.shape: {y_val.shape}\")\n",
        "# print(f\"X_test.shape: {X_test.shape}, y_test.shape: {y_test.shape}\")\n",
        "\n",
        "# # Feature Scaling (MinMaxScaler)\n",
        "# try:\n",
        "#     # Use cuML's MinMaxScaler if available\n",
        "#     from cuml.preprocessing import MinMaxScaler as cuMMScaler\n",
        "#     scaler = cuMMScaler()\n",
        "#     X_train_scaled = scaler.fit_transform(X_train)\n",
        "#     X_val_scaled = scaler.transform(X_val)\n",
        "#     X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# except ImportError:\n",
        "#     # Fallback to scikit-learn's MinMaxScaler if cuML is not available\n",
        "#     from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#     scaler = MinMaxScaler()\n",
        "#     X_train_scaled = scaler.fit_transform(X_train.to_pandas())  # Convert to pandas\n",
        "#     X_val_scaled = scaler.transform(X_val.to_pandas())       # Convert to pandas\n",
        "#     X_test_scaled = scaler.transform(X_test.to_pandas())      # Convert to pandas\n",
        "#     X_train_scaled = cudf.DataFrame(X_train_scaled)\n",
        "#     X_val_scaled = cudf.DataFrame(X_val_scaled)\n",
        "#     X_test_scaled = cudf.DataFrame(X_test_scaled)\n",
        "\n",
        "\n",
        "# # Create Directories to Save Datasets\n",
        "# base_dir = \"/kaggle/working/cb-en-p2aie22006\"\n",
        "# os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# train_dir = os.path.join(base_dir, \"train_data\")\n",
        "# val_dir = os.path.join(base_dir, \"val_data\")\n",
        "# test_dir = os.path.join(base_dir, \"test_data\")\n",
        "# os.makedirs(train_dir, exist_ok=True)\n",
        "# os.makedirs(val_dir, exist_ok=True)\n",
        "# os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "# # Save Train, Validation, and Test Data\n",
        "# X_train_scaled.to_csv(os.path.join(train_dir, \"train_features.csv\"), index=False)\n",
        "# np.savetxt(os.path.join(train_dir, \"train_labels.csv\"), y_train, delimiter=\",\")\n",
        "\n",
        "# X_val_scaled.to_csv(os.path.join(val_dir, \"val_features.csv\"), index=False)\n",
        "# np.savetxt(os.path.join(val_dir, \"val_labels.csv\"), y_val, delimiter=\",\")\n",
        "\n",
        "# X_test_scaled.to_csv(os.path.join(test_dir, \"test_features.csv\"), index=False)\n",
        "# np.savetxt(os.path.join(test_dir, \"test_labels.csv\"), y_test, delimiter=\",\")\n",
        "\n",
        "# print(\"Completed scaling\")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "1fKg5YG4u1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # dyn_mjpu1.py (Complete IDS Model with ML, RL, and DL on Kaggle)\n",
        "\n",
        "# import cudf\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import os\n",
        "\n",
        "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "# from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "# from imblearn.over_sampling import ADASYN\n",
        "# from sklearn.ensemble import VotingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
        "# from sklearn.metrics import (\n",
        "#     classification_report, confusion_matrix, make_scorer, matthews_corrcoef,\n",
        "# )\n",
        "# from datetime import datetime\n",
        "# from stable_baselines3 import PPO\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D\n",
        "# from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "\n",
        "\n",
        "# # 1. Data Loading and Preprocessing\n",
        "# # -----------------------------------\n",
        "\n",
        "# # Load the dataset from Kaggle input path\n",
        "# file_path = \"/kaggle/input/cb-en-p2aie22006/X-IIoTID dataset.csv\"\n",
        "# xiom1 = cudf.read_csv(file_path)  # Use cuDF directly\n",
        "# print(\"cuDF successfully loaded the dataset!\")\n",
        "\n",
        "# # ... (Drop unnecessary columns, filter for relevant attacks, and label encoding)\n",
        "\n",
        "# # ... (One-Hot Encode Categorical Features with cuML)\n",
        "\n",
        "# # ... (Resample using ADASYN)\n",
        "\n",
        "# # Split Data\n",
        "# X_train, X_temp, y_train, y_temp = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "# X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# # Feature Scaling (MinMaxScaler)\n",
        "# # ... (Use cuML's MinMaxScaler if available, otherwise convert to Pandas and use scikit-learn's MinMaxScaler)\n",
        "\n",
        "# # ... (Save Train, Validation, and Test Data)\n",
        "\n",
        "\n",
        "# # 2. Function Definitions\n",
        "# # -------------------------\n",
        "# # Define get_attack_labels(y_true, y_pred, attack_names, le):\n",
        "\n",
        "# # Define evaluate_and_plot(model, X_test, y_test, title, specific_attacks=None)\n",
        "\n",
        "# # 3. Machine Learning Model Training and Evaluation on Original Features\n",
        "# # ----------------------------------------------------------------------\n",
        "# with strategy.scope():\n",
        "#     # Define the parameter grid for both RandomForest and ExtraTrees classifiers\n",
        "#     param_grid = {\n",
        "#         'n_estimators': [50, 100, 200],\n",
        "#         'max_depth': [None, 10, 20, 30],\n",
        "#         'min_samples_split': [2, 5, 10],\n",
        "#         'min_samples_leaf': [1, 2, 4],\n",
        "#         'bootstrap': [True, False]\n",
        "#     }\n",
        "\n",
        "#     mcc_scorer = make_scorer(matthews_corrcoef)\n",
        "\n",
        "#     # Lists to store models and their names\n",
        "#     models_union = []\n",
        "#     model_names_union = []\n",
        "\n",
        "#     # Train and evaluate ML models on the original scaled features (X_train_scaled, X_val_scaled)\n",
        "#     # ... (Use GridSearchCV for hyperparameter tuning with cuML models)\n",
        "\n",
        "#     # Voting Classifier using models trained on original features\n",
        "#     # ... (Train and evaluate Voting Classifier on X_train_scaled and X_val_scaled)\n",
        "\n",
        "#     # Feature Selection based on Union of Top Features from RF and ET\n",
        "#     # ... (Select top_k features from both models, combine them, create X_train_union, X_val_union, X_test_union)\n",
        "\n",
        "#     # Retrain and evaluate ML models on the union of features (X_train_union, X_val_union)\n",
        "#     # ... (Use GridSearchCV for hyperparameter tuning with cuML models)\n",
        "\n",
        "# # 4. Reinforcement Learning-Based Feature Selection\n",
        "# # ---------------------------------------------------\n",
        "\n",
        "# # Define FeatureSelectionEnv class (using X_train_scaled and y_train for RL agent training)\n",
        "# # ...\n",
        "\n",
        "# # Set up RL environment\n",
        "# # ... (using X_train_union and y_train for RL agent training)\n",
        "# # Build and train RL model for Feature Selection\n",
        "# # ...\n",
        "# # Use the best RL-selected features\n",
        "# # ... (Create X_train_reduced_rl, X_val_reduced_rl, X_test_reduced_rl)\n",
        "\n",
        "# # 5. Model Training and Evaluation with RL-selected Features (Modified for TPU)\n",
        "# # -------------------------------------------------------------\n",
        "# with strategy.scope():\n",
        "\n",
        "#     # Train and Evaluate Random Forest Model on RL Features\n",
        "#     # ... (Train on X_train_reduced_rl, evaluate on X_val_reduced_rl)\n",
        "\n",
        "#     # Train and Evaluate Extra Trees Model on RL Features\n",
        "#     # ... (Train on X_train_reduced_rl, evaluate on X_val_reduced_rl)\n",
        "\n",
        "#     # Voting Classifier using models trained on RL-selected features\n",
        "#     # ... (Train on X_train_reduced_rl, evaluate on X_val_reduced_rl)\n",
        "\n",
        "# # 6. Deep Learning Model Training and Evaluation\n",
        "# # -----------------------------------------------\n",
        "# with strategy.scope():\n",
        "#     # Basic Deep Learning Model (Trained on X_train_union)\n",
        "#     # ... (same as before)\n",
        "\n",
        "#     # Transfer Learning Model (VGG16) - (Trained on X_train_union)\n",
        "#     # ... (same as before)\n",
        "\n",
        "\n",
        "# # 7. Evaluate All Models on the Test Set\n",
        "# # ----------------------------------------\n",
        "# models = models_union + models_rl + [best_model, model_transfer]\n",
        "# model_names = model_names_union + model_names_rl + ['Deep Learning (Basic)', 'Deep Learning (Transfer)']\n",
        "\n",
        "# specific_attacks = ['C&C', 'Modbus/TCP', 'DoS']\n",
        "\n",
        "# for i, model in enumerate(models):\n",
        "#     # ... (Evaluate each model on the appropriate test set (X_test or X_test_reduced_rl), using y_test)\n",
        "\n",
        "# # 8. Additional Analysis (Best Model Selection and Final Evaluation)\n",
        "# # ------------------------------------------------------------------\n",
        "# # Get the best model based on validation accuracy from all models (union, RL, and DL)\n",
        "# # ...\n",
        "\n",
        "# # Final Evaluation on Test Set\n",
        "# # ...\n",
        "# # Print best parameters for all models\n",
        "# # ...\n",
        "# # Save the best model to Kaggle Output\n",
        "# # ...\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "wARdx79Fu1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dyn_mjpu1.py (Complete IDS Model with ML, RL, and DL on Kaggle)\n",
        "\n",
        "# Part 1: Data Loading and Preprocessing\n",
        "# -----------------------------------\n",
        "# ... (Load the dataset using cuDF)\n",
        "\n",
        "# ... (Drop unnecessary columns)\n",
        "# df = df.drop(columns=['Timestamp', 'Date', 'class2', 'class3'])\n",
        "\n",
        "# Calculate Value Counts Before Filtering\n",
        "# ... (same as before)\n",
        "\n",
        "# Apply Threshold for Removing Low Sample Attacks (optional)\n",
        "# ... (Apply a threshold to filter out low sample attacks if desired)\n",
        "\n",
        "# Label Encoding (include \"Normal\")\n",
        "# ... (same as before, but ensure \"Normal\" is included in label encoding)\n",
        "\n",
        "# One-Hot Encode Categorical Features (excluding class1) - Using GPU\n",
        "# ... (same as before)\n",
        "\n",
        "# Resampling (ADASYN):\n",
        "# ... (same as before)\n",
        "\n",
        "# Split Data\n",
        "# X_train, X_temp, y_train, y_temp = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "# X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# ... (Feature Scaling using MinMaxScaler)\n",
        "\n",
        "# ... (Save Train, Validation, and Test Data)\n",
        "\n",
        "\n",
        "# 2. Function Definitions\n",
        "# -------------------------\n",
        "# Define get_attack_labels(y_true, y_pred, attack_names, le):\n",
        "\n",
        "# Define evaluate_and_plot(model, X_test, y_test, title, specific_attacks=None):\n",
        "#     ... (Add logic to filter out \"Normal\" instances from y_test and y_pred\n",
        "#          when calculating validation accuracy)\n",
        "\n",
        "# Part 3: Machine Learning Model Training and Evaluation on Original Features\n",
        "# ... (Use X_train_scaled, y_train, and X_val_scaled for model training and evaluation)\n",
        "\n",
        "# Part 4: Feature Selection (Union of Top Features and RL-based)\n",
        "# ... (Select top_k features from both models, combine them, create X_train_union, X_val_union, X_test_union)\n",
        "# ... (Use X_train_union and y_train for RL agent training)\n",
        "\n",
        "# Part 5:  Model Training and Evaluation with Feature Selection\n",
        "# ... (Retrain and evaluate ML models on the union of features and RL-selected features)\n",
        "\n",
        "# Part 6: Deep Learning Model Training and Evaluation\n",
        "# ... (Train and evaluate DL models on X_train_union, X_val_union, and X_test_union)\n",
        "\n",
        "# Part 7: Evaluate All Models on the Test Set\n",
        "# ... (Evaluate all models on X_test_union and X_test_reduced_rl as appropriate)\n",
        "\n",
        "\n",
        "# Part 8: Additional Analysis (Best Model Selection and Final Evaluation)\n",
        "# ------------------------------------------------------------------\n",
        "# ... (Select the best model based on validation accuracy EXCLUDING \"Normal\")\n",
        "# ... (Final Evaluation on Test Set)\n",
        "# ... (Print Best Parameters for All Models)\n",
        "# ... (Save the Best Model to Kaggle Output)\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "WCXkI3k1u1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # dyn_mjpu6_pt4.py (Deep Learning and Final Evaluation)\n",
        "# # ... (all imports from dyn_mjpu6_pt1.py and dyn_mjpu6_pt2.py)\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D\n",
        "# from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "\n",
        "\n",
        "# # 7. Deep Learning Model Training and Evaluation on Test Data\n",
        "# # ------------------------------------------------------------\n",
        "\n",
        "# # Define deep learning models with transfer learning and without\n",
        "# def create_cnn_model(input_shape):\n",
        "#     model = Sequential([\n",
        "#         Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "#         MaxPooling1D(pool_size=2),\n",
        "#         Flatten(),\n",
        "#         Dense(128, activation='relu'),\n",
        "#         Dropout(0.5),\n",
        "#         Dense(64, activation='relu'),\n",
        "#         Dropout(0.5),\n",
        "#         Dense(1, activation='sigmoid')  # Binary classification\n",
        "#     ])\n",
        "#     return model\n",
        "\n",
        "# # Create and train the base model\n",
        "# with strategy.scope():\n",
        "#     model = create_cnn_model(input_shape=(X_train_scaled.shape[1], 1))\n",
        "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#     # ModelCheckpoint callback to save the best model based on validation accuracy\n",
        "#     model_checkpoint = ModelCheckpoint(\n",
        "#         filepath=\"/kaggle/working/best_model_dl.h5\",\n",
        "#         save_best_only=True,\n",
        "#         monitor=\"val_accuracy\",\n",
        "#         mode=\"max\",\n",
        "#         verbose=1\n",
        "#     )\n",
        "\n",
        "#     model.fit(\n",
        "#         X_train_scaled.to_pandas(), y_train, epochs=10, batch_size=32,\n",
        "#         validation_data=(X_val_scaled.to_pandas(), y_val), callbacks=[model_checkpoint, tensorboard_callback]\n",
        "#     )\n",
        "#     best_model_dl = load_model(\"/kaggle/working/best_model_dl.h5\")\n",
        "\n",
        "#     # Transfer Learning Model (VGG16) - (Trained on X_train_union)\n",
        "#     # Reshape for VGG16 (assuming 128x128 input)\n",
        "#     X_train_union_reshaped = X_train_union.to_pandas().to_numpy()\n",
        "#     X_train_union_reshaped = tf.image.resize(X_train_union_reshaped, [128, 128])\n",
        "#     X_train_union_reshaped = tf.repeat(X_train_union_reshaped[..., np.newaxis], 3, -1)\n",
        "#     X_val_union_reshaped = X_val_union.to_pandas().to_numpy()\n",
        "#     X_val_union_reshaped = tf.image.resize(X_val_union_reshaped, [128, 128])\n",
        "#     X_val_union_reshaped = tf.repeat(X_val_union_reshaped[..., np.newaxis], 3, -1)\n",
        "\n",
        "#     # Load pre-trained VGG16 model\n",
        "#     base_model = tf.keras.applications.VGG16(\n",
        "#         weights='imagenet', include_top=False, input_shape=(128, 128, 3)\n",
        "#     )\n",
        "#     base_model.trainable = False  # Freeze base model layers\n",
        "\n",
        "#     model_transfer = Sequential([\n",
        "#         base_model,\n",
        "#         Flatten(),\n",
        "#         Dense(256, activation='relu'),\n",
        "#         Dropout(0.5),\n",
        "#         Dense(128, activation='relu'),\n",
        "#         Dropout(0.5),\n",
        "#         Dense(1, activation='sigmoid')  # Binary classification\n",
        "#     ])\n",
        "\n",
        "#     model_transfer.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#     model_transfer_history = model_transfer.fit(\n",
        "#         X_train_union_reshaped, y_train, epochs=10, batch_size=32,\n",
        "#         validation_data=(X_val_union_reshaped, y_val)\n",
        "#     )\n",
        "\n",
        "\n",
        "\n",
        "# # 7. Evaluate All Models on the Test Set\n",
        "# models = models_union + models_rl + [best_model_dl, model_transfer]\n",
        "# model_names = model_names_union + model_names_rl + ['Deep Learning (Basic)', 'Deep Learning (Transfer)']\n",
        "\n",
        "# specific_attacks = ['C&C', 'Modbus/TCP', 'DoS']\n",
        "\n",
        "# for i, model in enumerate(models):\n",
        "#     if isinstance(model, Sequential):  # Check if it's a deep learning model\n",
        "#         X_test_np = X_test_scaled.to_numpy()\n",
        "#         evaluate_and_plot(model, X_test_np, y_test, model_names[i], specific_attacks)  # Evaluate on test data\n",
        "#     else:\n",
        "#         if \"RL\" in model_names[i]:\n",
        "#             X_test_df = X_test_reduced_rl.to_pandas()\n",
        "#         else:\n",
        "#             X_test_df = X_test_union.to_pandas()\n",
        "#         evaluate_and_plot(model, X_test_df, y_test, model_names[i], specific_attacks)  # Evaluate on test data\n",
        "\n",
        "\n",
        "# # 8. Additional Analysis (Best Model Selection and Final Evaluation)\n",
        "# # ------------------------------------------------------------------\n",
        "\n",
        "# # Lists to store all models and their names (union, rl, and DL)\n",
        "# all_models = models_union + models_rl\n",
        "# all_model_names = model_names_union + model_names_rl\n",
        "# all_x_values = [X_val_union.to_pandas()] * 3 + [X_val_reduced_rl.to_pandas()] * 3\n",
        "\n",
        "\n",
        "# all_model_accuracies = [\n",
        "#     grid_search_rf.best_score_,\n",
        "#     grid_search_et.best_score_,\n",
        "#     voting_clf_union.score(X_val_union.to_pandas(), y_val),\n",
        "#     max(model_history.history['val_accuracy']),\n",
        "#     max(model_transfer_history.history['val_accuracy']),\n",
        "#     grid_search_rf_rl.best_score_,\n",
        "#     grid_search_et_rl.best_score_,\n",
        "#     voting_clf_rl.score(X_val_reduced_rl.to_pandas(), y_val) # Convert to pandas\n",
        "# ]\n",
        "\n",
        "# best_model_idx = np.argmax(all_model_accuracies)\n",
        "# best_model = models[best_model_idx]\n",
        "# best_model_name = model_names[best_model_idx]\n",
        "\n",
        "# print(f\"\\nBest Model based on Validation Accuracy: {best_model_name}\")\n",
        "# print(f\"\\nBest Model's Validation Accuracy: {np.max(all_model_accuracies)}\")\n",
        "# print(f\"\\nBest Model's Test Accuracy: {all_model_accuracies[best_model_idx]}\")\n",
        "\n",
        "\n",
        "# # Final Evaluation on Test Set\n",
        "# if best_model_name in ['Deep Learning (Basic)', 'Deep Learning (Transfer)']:\n",
        "#     y_pred_best = (best_model.predict(X_test_scaled.to_numpy()) > 0.5).astype(int)\n",
        "# else:\n",
        "#     X_test_best = (\n",
        "#         X_test_scaled if best_model_idx < 3 else X_test_reduced_rl\n",
        "#     )  # Choose the right test set based on the best model\n",
        "#     y_pred_best = best_model.predict(X_test_best.to_pandas())\n",
        "\n",
        "# print(f\"\\nFinal Test Set Classification Report ({best_model_name}):\\n\", classification_report(y_test, y_pred_best, target_names=le.classes_))\n",
        "\n",
        "# # Print best parameters for Random Forest and Extra Trees models\n",
        "# print(f\"\\nBest Random Forest Parameters: {grid_search_rf.best_params_}\")\n",
        "# print(f\"\\nBest Extra Trees Parameters: {grid_search_et.best_params_}\")\n",
        "# print(f\"\\nBest Random Forest (RL features) Parameters: {grid_search_rf_rl.best_params_}\")\n",
        "# print(f\"\\nBest Extra Trees (RL features) Parameters: {grid_search_et_rl.best_params_}\")\n",
        "\n",
        "# # Save the best model to Kaggle Output\n",
        "# if isinstance(best_model, Sequential):\n",
        "#     best_model.save(\"best_model.h5\")\n",
        "# else:\n",
        "#     import joblib\n",
        "#     joblib.dump(best_model, 'best_model.pkl')\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "UxWq93mpu1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#<dynm_xpu_1>\n",
        "# import warnings\n",
        "\n",
        "# # Filter DeprecationWarnings to avoid cluttering output\n",
        "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# # Filter DtypeWarnings that might arise from mismatched data types\n",
        "# # (e.g., when converting between cuDF and Pandas)\n",
        "# warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "\n",
        "# import cudf\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import os\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "# from imblearn.over_sampling import ADASYN\n",
        "# from cuml.preprocessing import OneHotEncoder\n",
        "# import warnings\n",
        "# # TensorFlow TPU/GPU Setup\n",
        "# try:\n",
        "#   resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "#   tf.config.experimental_connect_to_cluster(resolver)\n",
        "#   tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "#   strategy = tf.distribute.TPUStrategy(resolver)\n",
        "#   print(\"Running on TPU:\", resolver.cluster_spec().as_dict()['worker'])\n",
        "# except ValueError:\n",
        "#   strategy = tf.distribute.get_strategy() # Default strategy for CPU and single GPU\n",
        "#   print(\"Running on CPU/GPU\")\n",
        "\n",
        "\n",
        "# # Filter DeprecationWarnings to avoid cluttering output\n",
        "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# # Filter DtypeWarnings that might arise from mismatched data types\n",
        "# # (e.g., when converting between cuDF and Pandas)\n",
        "# warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# # 1. Data Loading and Preprocessing\n",
        "# # -----------------------------------\n",
        "\n",
        "# # Load the dataset from Kaggle input path\n",
        "# file_path = \"/kaggle/input/cb-en-p2aie22006-manojvs/X-IIoTID dataset.csv\"\n",
        "\n",
        "# # Read the dataset using cuDF\n",
        "# xiom1 = cudf.read_csv(file_path)\n",
        "# print(\"cuDF successfully loaded the dataset!\")\n",
        "\n",
        "# # Drop unnecessary columns\n",
        "# xiom1 = xiom1.drop(columns=['Timestamp', 'Date', 'class2', 'class3'])\n",
        "# print(xiom1.shape)\n",
        "\n",
        "# # Calculate Value Counts Before Filtering\n",
        "# class_counts = xiom1['class1'].value_counts()\n",
        "# print(\"\\nValue counts for each class label in Class1:\")\n",
        "# class_counts_df = class_counts.reset_index()\n",
        "# class_counts_df.columns = [\"Class\", \"Count\"]\n",
        "# print(class_counts_df.to_pandas().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "# # Apply Threshold for Removing Low Sample Attacks (optional)\n",
        "# threshold = 0.05 * class_counts.max()\n",
        "\n",
        "# # Filter classes that meet the threshold\n",
        "# filtered_counts = class_counts[class_counts >= threshold]\n",
        "# print(f\"\\nFiltered classes with counts above {threshold}:\")\n",
        "# print(filtered_counts.to_pandas().to_markdown(numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "# # Filter the original DataFrame based on filtered_counts\n",
        "# xiom1_filtered = xiom1[xiom1['class1'].isin(filtered_counts.index)]\n",
        "\n",
        "# # Recalculate Value Counts After Filtering\n",
        "# class_counts_filtered = xiom1_filtered['class1'].value_counts()\n",
        "# print(\"\\nValue counts for each filtered class label in Class1:\")\n",
        "# class_counts_filtered_df = class_counts_filtered.reset_index()\n",
        "# class_counts_filtered_df.columns = [\"Class\", \"Count\"]\n",
        "# print(class_counts_filtered_df.to_pandas().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "\n",
        "# # Label Encoding (include \"Normal\")\n",
        "# le = LabelEncoder()\n",
        "# y_filtered = le.fit_transform(xiom1_filtered['class1'].to_arrow().to_pylist())\n",
        "\n",
        "# # One-Hot Encode Categorical Features (excluding class1) - Using GPU\n",
        "# encoder = OneHotEncoder()\n",
        "# X_filtered = encoder.fit_transform(xiom1_filtered.drop(columns=['class1']))  # cuDF DataFrame remains in GPU\n",
        "\n",
        "# # Manually drop the first column to avoid multicollinearity\n",
        "# X_filtered = X_filtered.drop(X_filtered.columns[0])  # Correctly drop the first column using cuDF syntax\n",
        "\n",
        "# # Resampling (ADASYN):\n",
        "# adasyn = ADASYN(random_state=42)\n",
        "# X_resampled, y_resampled = adasyn.fit_resample(X_filtered.to_pandas(), y_filtered)  # Convert to pandas for compatibility\n",
        "# X_resampled = cudf.DataFrame(X_resampled)  # Convert back to cuDF\n",
        "\n",
        "# # Split Data\n",
        "# X_train, X_temp, y_train, y_temp = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "# X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "# print(f\"X_train.shape: {X_train.shape}, y_train.shape: {y_train.shape}\")\n",
        "# print(f\"X_val.shape: {X_val.shape}, y_val.shape: {y_val.shape}\")\n",
        "# print(f\"X_test.shape: {X_test.shape}, y_test.shape: {y_test.shape}\")\n",
        "\n",
        "# # Feature Scaling (MinMaxScaler)\n",
        "# try:\n",
        "#     # Use cuML's MinMaxScaler if available\n",
        "#     from cuml.preprocessing import MinMaxScaler as cuMMScaler\n",
        "#     scaler = cuMMScaler()\n",
        "#     X_train_scaled = scaler.fit_transform(X_train)\n",
        "#     X_val_scaled = scaler.transform(X_val)\n",
        "#     X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# except ImportError:\n",
        "#     # Fallback to scikit-learn's MinMaxScaler if cuML is not available\n",
        "#     from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#     scaler = MinMaxScaler()\n",
        "#     X_train_scaled = scaler.fit_transform(X_train.to_pandas())  # Convert to pandas\n",
        "#     X_val_scaled = scaler.transform(X_val.to_pandas())       # Convert to pandas\n",
        "#     X_test_scaled = scaler.transform(X_test.to_pandas())      # Convert to pandas\n",
        "#     X_train_scaled = cudf.DataFrame(X_train_scaled)\n",
        "#     X_val_scaled = cudf.DataFrame(X_val_scaled)\n",
        "#     X_test_scaled = cudf.DataFrame(X_test_scaled)\n",
        "\n",
        "\n",
        "# # Create Directories to Save Datasets\n",
        "# base_dir = \"/kaggle/working/cb-en-p2aie22006\"\n",
        "# os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# train_dir = os.path.join(base_dir, \"train_data\")\n",
        "# val_dir = os.path.join(base_dir, \"val_data\")\n",
        "# test_dir = os.path.join(base_dir, \"test_data\")\n",
        "# os.makedirs(train_dir, exist_ok=True)\n",
        "# os.makedirs(val_dir, exist_ok=True)\n",
        "# os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "# # Save Train, Validation, and Test Data\n",
        "# X_train_scaled.to_csv(os.path.join(train_dir, \"train_features.csv\"), index=False)\n",
        "# np.savetxt(os.path.join(train_dir, \"train_labels.csv\"), y_train, delimiter=\",\")\n",
        "\n",
        "# X_val_scaled.to_csv(os.path.join(val_dir, \"val_features.csv\"), index=False)\n",
        "# np.savetxt(os.path.join(val_dir, \"val_labels.csv\"), y_val, delimiter=\",\")\n",
        "\n",
        "# X_test_scaled.to_csv(os.path.join(test_dir, \"test_features.csv\"), index=False)\n",
        "# np.savetxt(os.path.join(test_dir, \"test_labels.csv\"), y_test, delimiter=\",\")\n",
        "\n",
        "# print(\"Completed scaling\")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "I4Hjxjmqu1Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #<dynamic_xiiot_pt1>\n",
        "# import warnings\n",
        "\n",
        "# # Filter DeprecationWarnings to avoid cluttering output\n",
        "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# # Filter DtypeWarnings that might arise from mismatched data types\n",
        "# # (e.g., when converting between cuDF and Pandas)\n",
        "# warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# import cudf\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import os\n",
        "# from tabulate import tabulate\n",
        "\n",
        "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "# from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "# from imblearn.over_sampling import ADASYN\n",
        "# from cuml.preprocessing import OneHotEncoder\n",
        "# from sklearn.ensemble import VotingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
        "# from sklearn.metrics import (\n",
        "#     classification_report, confusion_matrix, make_scorer, matthews_corrcoef,\n",
        "# )\n",
        "# from datetime import datetime\n",
        "# from stable_baselines3 import PPO\n",
        "\n",
        "\n",
        "# # TensorFlow TPU/GPU Setup\n",
        "# try:\n",
        "#     resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "#     tf.config.experimental_connect_to_cluster(resolver)\n",
        "#     tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "#     strategy = tf.distribute.TPUStrategy(resolver)\n",
        "#     print(\"Running on TPU:\", resolver.cluster_spec().as_dict()['worker'])\n",
        "# except ValueError:\n",
        "#     strategy = tf.distribute.get_strategy()  # Default strategy for CPU and single GPU\n",
        "#     print(\"Running on CPU/GPU\")\n",
        "\n",
        "#     # Load the dataset from Kaggle input path\n",
        "# file_path = \"/kaggle/input/cb-en-p2aie22006-manojvs/X-IIoTID dataset.csv\"\n",
        "# # Read the dataset using cuDF\n",
        "# xiom1 = cudf.read_csv(file_path)\n",
        "# print(\"cuDF successfully loaded the dataset!\")\n",
        "\n",
        "# # Drop unnecessary columns\n",
        "# xiom1 = xiom1.drop(columns=['Timestamp', 'Date', 'class2', 'class3'])\n",
        "# print(xiom1.shape)\n",
        "\n",
        "# # Get string columns\n",
        "# string_columns = xiom1.select_dtypes(include='object').columns\n",
        "\n",
        "# print(\"\\nString Columns:\")\n",
        "# print(list(string_columns))  # Convert to list directly for printing\n",
        "\n",
        "# print(\"\\nAll Columns:\")\n",
        "# print(list(xiom1.columns))  # Convert to list directly for printing\n",
        "\n",
        "# import cudf\n",
        "\n",
        "# # Assuming you have a cuDF DataFrame called `xiom1`\n",
        "# # ... (your existing code)\n",
        "\n",
        "# # Count of string columns\n",
        "# num_string_cols = xiom1.select_dtypes(include='object').shape[1]\n",
        "# print(\"Count of string columns:\", num_string_cols)\n",
        "\n",
        "# # Count of all columns\n",
        "# num_all_cols = len(xiom1.columns)\n",
        "# print(\"Count of all columns:\", num_all_cols)\n",
        "\n",
        "# # Count of numeric columns (excluding boolean)\n",
        "# numeric_columns = xiom1.select_dtypes(include=['int8', 'int16', 'int32', 'int64', 'float32', 'float64']).columns\n",
        "# print(\"\\nNumeric Columns:\")\n",
        "# print(list(numeric_columns))\n",
        "\n",
        "# # Count of numeric columns (excluding boolean)\n",
        "# num_numeric_cols = len(numeric_columns)\n",
        "# print(\"Count of numeric columns:\", num_numeric_cols)\n",
        "\n",
        "\n",
        "# # Calculate Value Counts Before Filtering , class_counts ---> cc , class_counts_df -->cc_df\n",
        "# cc = xiom1['class1'].value_counts()\n",
        "# print(\"\\nValue counts for each class label in Class1:\")\n",
        "# cc_df = cc.reset_index()\n",
        "# cc_df.columns = [\"Class\", \"Count\"]\n",
        "# print(cc_df.to_pandas().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "# # Apply Threshold for Removing Low Sample Attacks\n",
        "# threshold = 0.005 * cc.max()\n",
        "\n",
        "# # Filter classes that meet the threshold , filtered_counts ---> f_c\n",
        "# f_c = cc[cc >= threshold]\n",
        "# print(f\"\\nFiltered classes with counts above {threshold}:\")\n",
        "# print(f_c.to_pandas().to_markdown(numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "# # Filter the original DataFrame based on filtered_counts\n",
        "# xiom1_flt = xiom1[xiom1['class1'].isin(f_c.index)]\n",
        "# print(xiom1_flt.shape)\n",
        "\n",
        "# # Recalculate Value Counts After Filtering class_counts_filtered ---> ccf ,class_counts_filtered_to_pandas ---> ccf_pd\n",
        "# ccf = xiom1_flt['class1'].value_counts()\n",
        "# print(\"\\nValue counts for each filtered class label in Class1:\")\n",
        "# ccf_pd = ccf.reset_index()\n",
        "# ccf_pd.columns = [\"Class\", \"Count\"]\n",
        "# print(ccf_pd.to_pandas().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "# # Convert cuDF StringColumn to a list before encoding , string_labels ---> s_lb\n",
        "# s_lb = xiom1_flt['class1'].to_arrow().to_pylist()\n",
        "# LE = LabelEncoder()\n",
        "# y_flt = LE.fit_transform(s_lb)  # Extract values directly\n",
        "\n",
        "# # Display a limited number of unique labels and their counts using cudf.Series.value_counts()\n",
        "# def print_class_counts(cc, LE=None, verbose=5):\n",
        "#     \"\"\"Prints a limited number of class labels and their counts in a table.\n",
        "\n",
        "#     Args:\n",
        "#         cc: cuDF Series of class labels and counts.\n",
        "#         LE: LabelEncoder object (optional, used if labels are numeric).\n",
        "#         verbose (int): Number of top labels to display (default: 5).\n",
        "#     \"\"\"\n",
        "#     from tabulate import tabulate\n",
        "\n",
        "#     print(\"\\nCounts of Samples per Class (Top {}):\".format(verbose))\n",
        "\n",
        "#     # Check if input is a Series or DataFrame\n",
        "#     if isinstance(cc, cudf.DataFrame):\n",
        "#         cc_df = cc\n",
        "#     elif isinstance(cc, cudf.Series):\n",
        "#         cc_df = cc.reset_index(name='Count')\n",
        "#         cc_df = cc_df.rename(columns={'index': 'Class'})\n",
        "\n",
        "\n",
        "#     # Convert labels back to original class names if they are encoded\n",
        "#     if LE is not None and cc_df['Class'].dtype=='int64':\n",
        "#         cc_df['Class'] = cc_df['Class'].to_pandas().apply(lambda x: LE.inverse_transform([x])[0])\n",
        "\n",
        "#     # Convert to Pandas DataFrames for using tabulate\n",
        "#     cc_df = cc_df.to_pandas()\n",
        "#     cc_df = cc_df[['Class', 'Count']]  # Reorder columns\n",
        "\n",
        "#     # Display using tabulate\n",
        "#     print(tabulate(cc_df.head(verbose), headers='keys', tablefmt='pipe', showindex=False))\n",
        "\n",
        "# #Example Usage:\n",
        "# # Print Class Counts (Top 5 by default)\n",
        "# print_class_counts(xiom1_flt[\"class1\"].value_counts(), LE)\n",
        "\n",
        "# # Print Labels (Top 8 by default)\n",
        "# label_counts = pd.DataFrame(s_lb, columns=['class1']).groupby('class1').size().reset_index(name='Count')\n",
        "# print_class_counts(label_counts, verbose=8)  # Show top 8 labels\n",
        "\n",
        "# # Resampling (ADASYN):\n",
        "# adasyn = ADASYN(random_state=42)\n",
        "# X_resampled, y_resampled = adasyn.fit_resample(X_filtered.to_pandas(), y_filtered)  # Convert to pandas for compatibility\n",
        "# X_resampled = cudf.DataFrame(X_resampled)  # Convert back to cuDF\n",
        "\n",
        "# # Split Data\n",
        "# X_train, X_temp, y_train, y_temp = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "# X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# # Feature Scaling (MinMaxScaler)\n",
        "# scaler = MinMaxScaler()\n",
        "# X_train_scaled = scaler.fit_transform(X_train.to_pandas())\n",
        "# X_val_scaled = scaler.transform(X_val.to_pandas())\n",
        "# X_test_scaled = scaler.transform(X_test.to_pandas())\n",
        "\n",
        "# # Convert back to cudf Dataframes\n",
        "# X_train_scaled = cudf.DataFrame(X_train_scaled)\n",
        "# X_val_scaled = cudf.DataFrame(X_val_scaled)\n",
        "# X_test_scaled = cudf.DataFrame(X_test_scaled)\n",
        "\n",
        "# # Create Directories to Save Datasets\n",
        "# base_dir = \"/kaggle/working/cb-en-p2aie22006\"\n",
        "# os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# train_dir = os.path.join(base_dir, \"train_data\")\n",
        "# val_dir = os.path.join(base_dir, \"val_data\")\n",
        "# test_dir = os.path.join(base_dir, \"test_data\")\n",
        "# os.makedirs(train_dir, exist_ok=True)\n",
        "# os.makedirs(val_dir, exist_ok=True)\n",
        "# os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# # Save Train, Validation, and Test Data\n",
        "# X_train_scaled.to_csv(os.path.join(train_dir, \"train_features.csv\"), index=False)\n",
        "# np.savetxt(os.path.join(train_dir, \"train_labels.csv\"), y_train, delimiter=\",\")\n",
        "\n",
        "# X_val_scaled.to_csv(os.path.join(val_dir, \"val_features.csv\"), index=False)\n",
        "# np.savetxt(os.path.join(val_dir, \"val_labels.csv\"), y_val, delimiter=\",\")\n",
        "\n",
        "# X_test_scaled.to_csv(os.path.join(test_dir, \"test_features.csv\"), index=False)\n",
        "# np.savetxt(os.path.join(test_dir, \"test_labels.csv\"), y_test, delimiter=\",\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "0VoxKPkzu1Zi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}